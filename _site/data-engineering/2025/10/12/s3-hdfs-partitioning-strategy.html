<!DOCTYPE html>
<html lang="ko">
<head>
  <link rel="stylesheet" href="/assets/css/style.css">
  <!-- Head includes for Jekyll -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- SEO -->

<meta name="description" content="HDFS 시절의 yyyy/mm/dd 파티셔닝이 S3에서는 왜 성능 문제를 일으키는지, 그리고 S3에 최적화된 파티셔닝 전략과 실제 쿼리 성능 비교를 다룹니다.">



<title>S3 vs HDFS 파티셔닝 전략 - 클라우드 시대의 데이터 레이크 최적화 - Data Droid Blog</title>


<!-- Open Graph -->
<meta property="og:title" content="S3 vs HDFS 파티셔닝 전략 - 클라우드 시대의 데이터 레이크 최적화">
<meta property="og:description" content="HDFS 시절의 yyyy/mm/dd 파티셔닝이 S3에서는 왜 성능 문제를 일으키는지, 그리고 S3에 최적화된 파티셔닝 전략과 실제 쿼리 성능 비교를 다룹니다.">
<meta property="og:url" content="http://localhost:4000/data-engineering/2025/10/12/s3-hdfs-partitioning-strategy.html">
<meta property="og:type" content="website">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="S3 vs HDFS 파티셔닝 전략 - 클라우드 시대의 데이터 레이크 최적화">
<meta name="twitter:description" content="HDFS 시절의 yyyy/mm/dd 파티셔닝이 S3에서는 왜 성능 문제를 일으키는지, 그리고 S3에 최적화된 파티셔닝 전략과 실제 쿼리 성능 비교를 다룹니다.">

<!-- Favicon -->
<link rel="icon" type="image/svg+xml" href="/assets/favicon.svg">
<link rel="icon" type="image/x-icon" href="/favicon.ico">

<!-- RSS Feed -->
<link rel="alternate" type="application/rss+xml" title="Data Droid Blog" href="/feed.xml">

<!-- Google Analytics -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GP9LT745PP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GP9LT745PP');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <div class="site-title">
      <a href="/">Data Droid Blog</a>
    </div>
    
    <!-- Mobile menu toggle button -->
    <button class="mobile-menu-toggle" aria-label="메뉴 열기/닫기">
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
    </button>
    
    <nav class="site-nav">
      <ul class="nav-list">
        <li><a href="/">홈</a></li>
                  <li class="dropdown">
            <a href="#" class="dropdown-toggle">카테고리</a>
            <ul class="dropdown-menu">

              <li><a href="/categories/data-engineering/">데이터 엔지니어링</a></li>
              <li><a href="/categories/bi-engineering/">BI 엔지니어링</a></li>
              <li><a href="/categories/infrastructure-tools/">인프라 & 도구</a></li>
              <li><a href="/categories/data-quality/">데이터 품질</a></li>
              <li><a href="/categories/data-ai/">Data AI</a></li>
            </ul>
          </li>
        <li><a href="/blog/">블로그</a></li>
        <li><a href="/about/">소개</a></li>
      </ul>
    </nav>
    
    <div class="language-switcher">
      
        <!-- 포스트용 언어 전환 -->
        
          <a href="/data-engineering/2025/10/12/s3-hdfs-partitioning-strategy.html" class="lang-btn active">한국어</a>
          
          <a href="/en_posts/2025-10-12-s3-hdfs-partitioning-strategy.html" class="lang-btn">English</a>
        
      
    </div>
  </div>
</header>

  
  <main class="site-main">
    <div class="container">
      <article class="post">
  <header class="post-header">
    <div class="post-meta">
      <span class="post-category">Data engineering</span>
      <span class="post-date">2025년 10월 12일</span>
      <span class="post-author">Data Droid</span>
    </div>
    
    <h1 class="post-title">S3 vs HDFS 파티셔닝 전략 - 클라우드 시대의 데이터 레이크 최적화</h1>
    
    
    <div class="post-tags">
      
        <span class="tag">S3</span>
      
        <span class="tag">HDFS</span>
      
        <span class="tag">Partitioning</span>
      
        <span class="tag">DataLake</span>
      
        <span class="tag">CloudStorage</span>
      
        <span class="tag">Spark</span>
      
        <span class="tag">Athena</span>
      
        <span class="tag">Performance</span>
      
        <span class="tag">Optimization</span>
      
    </div>
    
    
    
    <div class="post-series">
      <span class="series-badge">📚 Cloud data architecture 시리즈</span>
      <span class="series-order">Part 2</span>
    </div>
    
    
    
    <div class="post-info">
      
        <span class="reading-time">⏱️ 50분</span>
      
      
        <span class="difficulty">📊 중급</span>
      
    </div>
    
  </header>

  <div class="post-content">
    <h1 id="️-s3-vs-hdfs-파티셔닝-전략---클라우드-시대의-데이터-레이크-최적화">🗄️ S3 vs HDFS 파티셔닝 전략 - 클라우드 시대의 데이터 레이크 최적화</h1>

<blockquote>
  <p><strong>“과거의 모범 사례가 현재의 안티패턴이 될 수 있다”</strong> - HDFS에서 S3로 마이그레이션할 때 반드시 알아야 할 파티셔닝 전략의 변화</p>
</blockquote>

<p>데이터 레이크를 온프레미스 HDFS에서 클라우드 S3로 마이그레이션하면서 많은 팀들이 기존의 <code class="language-plaintext highlighter-rouge">yyyy/mm/dd</code> 파티셔닝 구조를 그대로 유지합니다. 하지만 이는 S3의 아키텍처 특성상 심각한 성능 저하를 초래할 수 있습니다. 이 포스트에서는 HDFS와 S3의 근본적인 차이점을 이해하고, S3에 최적화된 파티셔닝 전략과 실제 쿼리 성능 비교를 통해 실무에 바로 적용할 수 있는 가이드를 제공합니다.</p>

<hr />

<h2 id="-목차">📚 목차</h2>

<ul>
  <li><a href="#hdfs-시대의-파티셔닝-전략">HDFS 시대의 파티셔닝 전략</a></li>
  <li><a href="#s3의-근본적인-차이점">S3의 근본적인 차이점</a></li>
  <li><a href="#s3-파티셔닝-안티패턴">S3 파티셔닝 안티패턴</a></li>
  <li><a href="#s3-최적화-파티셔닝-전략">S3 최적화 파티셔닝 전략</a></li>
  <li><a href="#실제-쿼리-성능-비교">실제 쿼리 성능 비교</a></li>
  <li><a href="#실무-마이그레이션-가이드">실무 마이그레이션 가이드</a></li>
  <li><a href="#학습-요약">학습 요약</a></li>
</ul>

<hr />

<h2 id="hdfs-시대의-파티셔닝-전략">🏛️ HDFS 시대의 파티셔닝 전략</h2>

<h3 id="hdfs-아키텍처-이해">HDFS 아키텍처 이해</h3>

<p>HDFS는 <strong>계층적 파일 시스템</strong>으로 설계되었습니다.</p>

<table>
  <thead>
    <tr>
      <th><strong>구성요소</strong></th>
      <th><strong>역할</strong></th>
      <th><strong>특징</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>NameNode</strong></td>
      <td>메타데이터 관리</td>
      <td>디렉토리 구조를 메모리에 저장</td>
    </tr>
    <tr>
      <td><strong>DataNode</strong></td>
      <td>실제 데이터 저장</td>
      <td>로컬 디스크 기반 블록 스토리지</td>
    </tr>
    <tr>
      <td><strong>Block</strong></td>
      <td>데이터 단위</td>
      <td>128MB 기본 크기, 복제본 유지</td>
    </tr>
  </tbody>
</table>

<h3 id="yyyymmdd가-적합했던-이유">yyyy/mm/dd가 적합했던 이유</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># HDFS의 전형적인 파티션 구조</span>
/data/events/
  └── <span class="nv">year</span><span class="o">=</span>2024/
      └── <span class="nv">month</span><span class="o">=</span>01/
          └── <span class="nv">day</span><span class="o">=</span>15/
              ├── part-00000.parquet
              ├── part-00001.parquet
              └── part-00002.parquet
</code></pre></div></div>

<h4 id="1-namenode-메타데이터-효율성"><strong>1. NameNode 메타데이터 효율성</strong></h4>
<ul>
  <li><strong>디렉토리 구조</strong>: 트리 구조로 메타데이터 관리</li>
  <li><strong>메모리 사용</strong>: 각 디렉토리/파일당 ~150 bytes</li>
  <li><strong>계층 탐색</strong>: O(log n) 시간 복잡도로 빠른 검색</li>
</ul>

<h4 id="2-hive-파티션-프루닝"><strong>2. Hive 파티션 프루닝</strong></h4>
<ul>
  <li><strong>동적 파티션</strong>: 날짜별 자동 파티셔닝</li>
  <li><strong>메타스토어</strong>: 파티션 메타데이터 캐싱</li>
  <li><strong>쿼리 최적화</strong>: WHERE 절로 불필요한 파티션 제외</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Hive에서 효율적인 쿼리</span>
<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">events</span>
<span class="k">WHERE</span> <span class="nb">year</span> <span class="o">=</span> <span class="mi">2024</span> <span class="k">AND</span> <span class="k">month</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">AND</span> <span class="k">day</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>
<span class="c1">-- NameNode는 즉시 해당 디렉토리로 이동 가능</span>
</code></pre></div></div>

<h4 id="3-로컬-디스크-특성"><strong>3. 로컬 디스크 특성</strong></h4>
<ul>
  <li><strong>순차 읽기</strong>: 디렉토리 구조 순회가 빠름</li>
  <li><strong>블록 지역성</strong>: DataNode가 로컬 데이터 우선 처리</li>
  <li><strong>네트워크 비용</strong>: 최소화</li>
</ul>

<h3 id="hdfs-파티셔닝-모범-사례">HDFS 파티셔닝 모범 사례</h3>

<table>
  <thead>
    <tr>
      <th><strong>전략</strong></th>
      <th><strong>설명</strong></th>
      <th><strong>장점</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>시간 기반</strong></td>
      <td>yyyy/mm/dd 또는 yyyy/mm/dd/hh</td>
      <td>시계열 데이터 효율적 처리</td>
    </tr>
    <tr>
      <td><strong>계층적 구조</strong></td>
      <td>카테고리별 중첩 디렉토리</td>
      <td>메타데이터 구조화</td>
    </tr>
    <tr>
      <td><strong>파티션 수</strong></td>
      <td>수천~수만 개도 가능</td>
      <td>NameNode 메모리만 충분하면 OK</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="s3의-근본적인-차이점">☁️ S3의 근본적인 차이점</h2>

<h3 id="s3는-객체-스토리지다">S3는 객체 스토리지다</h3>

<p>S3는 <strong>파일 시스템이 아닌 Key-Value 객체 스토리지</strong>입니다.</p>

<table>
  <thead>
    <tr>
      <th><strong>특성</strong></th>
      <th><strong>HDFS</strong></th>
      <th><strong>S3</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>저장 방식</strong></td>
      <td>계층적 파일 시스템</td>
      <td>Flat namespace (Key-Value)</td>
    </tr>
    <tr>
      <td><strong>디렉토리</strong></td>
      <td>실제 디렉토리 존재</td>
      <td>디렉토리는 개념적 (Key의 일부)</td>
    </tr>
    <tr>
      <td><strong>메타데이터</strong></td>
      <td>NameNode 메모리</td>
      <td>분산 메타데이터 스토어</td>
    </tr>
    <tr>
      <td><strong>접근 방식</strong></td>
      <td>파일 경로</td>
      <td>Object Key</td>
    </tr>
    <tr>
      <td><strong>List 연산</strong></td>
      <td>빠름 (로컬 디스크)</td>
      <td>느림 (네트워크 API 호출)</td>
    </tr>
  </tbody>
</table>

<h3 id="s3의-내부-구조">S3의 내부 구조</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># S3에서는 "디렉토리"가 실제로 존재하지 않음
# 모든 것이 Key-Value 쌍
</span><span class="n">s3</span><span class="p">:</span><span class="o">//</span><span class="n">bucket</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">events</span><span class="o">/</span><span class="n">year</span><span class="o">=</span><span class="mi">2024</span><span class="o">/</span><span class="n">month</span><span class="o">=</span><span class="mi">01</span><span class="o">/</span><span class="n">day</span><span class="o">=</span><span class="mi">15</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="mf">00000.</span><span class="n">parquet</span>
<span class="c1"># 위는 실제로 하나의 긴 Key일 뿐
</span></code></pre></div></div>

<h4 id="s3-list-연산의-비용"><strong>S3 List 연산의 비용</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">boto3</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="nf">client</span><span class="p">(</span><span class="sh">'</span><span class="s">s3</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># yyyy/mm/dd 구조에서 특정 날짜 데이터 찾기
# 1. year=2024 리스트 -&gt; API 호출 1회
# 2. month=01 리스트 -&gt; API 호출 1회  
# 3. day=15 리스트 -&gt; API 호출 1회
# 총 3번의 API 호출 + 네트워크 레이턴시
</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">s3</span><span class="p">.</span><span class="nf">list_objects_v2</span><span class="p">(</span>
    <span class="n">Bucket</span><span class="o">=</span><span class="sh">'</span><span class="s">my-bucket</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">Prefix</span><span class="o">=</span><span class="sh">'</span><span class="s">data/events/year=2024/month=01/day=15/</span><span class="sh">'</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="s3-성능-특성">S3 성능 특성</h3>

<h4 id="1-request-rate-제한"><strong>1. Request Rate 제한</strong></h4>
<ul>
  <li><strong>Prefix당 처리량</strong>: 3,500 PUT/COPY/POST/DELETE, 5,500 GET/HEAD 요청/초</li>
  <li><strong>깊은 디렉토리 구조</strong>: 동일 Prefix로 집중되어 병목 발생</li>
  <li><strong>성능 저하</strong>: 많은 List 연산 시 급격한 응답 시간 증가</li>
</ul>

<h4 id="2-list-연산-오버헤드"><strong>2. List 연산 오버헤드</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>연산</strong></th>
      <th><strong>HDFS</strong></th>
      <th><strong>S3</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>단일 디렉토리 List</strong></td>
      <td>~1ms (로컬)</td>
      <td>~100-300ms (네트워크)</td>
    </tr>
    <tr>
      <td><strong>깊이 3 탐색</strong></td>
      <td>~3ms</td>
      <td>~300-900ms</td>
    </tr>
    <tr>
      <td><strong>1,000개 객체 List</strong></td>
      <td>~10ms</td>
      <td>~1-2초</td>
    </tr>
  </tbody>
</table>

<h4 id="3-eventually-consistent-특성"><strong>3. Eventually Consistent 특성</strong></h4>
<ul>
  <li><strong>쓰기 후 읽기</strong>: 새 객체는 즉시 일관성 보장 (2020년 12월 이후)</li>
  <li><strong>덮어쓰기/삭제</strong>: 최종 일관성 (약간의 지연 가능)</li>
  <li><strong>List 연산</strong>: 최신 변경사항이 즉시 반영되지 않을 수 있음</li>
</ul>

<hr />

<h2 id="s3-파티셔닝-안티패턴">⚠️ S3 파티셔닝 안티패턴</h2>

<h3 id="안티패턴-1-과도하게-깊은-계층-구조">안티패턴 #1: 과도하게 깊은 계층 구조</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 안티패턴: HDFS 스타일 그대로 사용</span>
s3://bucket/data/events/
  └── <span class="nv">year</span><span class="o">=</span>2024/
      └── <span class="nv">month</span><span class="o">=</span>01/
          └── <span class="nv">day</span><span class="o">=</span>15/
              └── <span class="nv">hour</span><span class="o">=</span>10/
                  ├── part-00000.parquet
                  └── part-00001.parquet
</code></pre></div></div>

<h4 id="문제점"><strong>문제점</strong></h4>
<ul>
  <li><strong>List 연산 폭증</strong>: 각 레벨마다 API 호출 필요</li>
  <li><strong>네트워크 레이턴시</strong>: 4-5번의 왕복 시간 누적</li>
  <li><strong>쿼리 지연</strong>: Spark/Athena가 파티션 탐색에 과도한 시간 소비</li>
</ul>

<h4 id="실제-영향"><strong>실제 영향</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spark에서 파티션 탐색 시간 측정
</span><span class="kn">import</span> <span class="n">time</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/year=2024/month=01/day=15/</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Partition discovery: </span><span class="si">{</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># 결과: Partition discovery: 5.43s (깊은 구조)
# vs
# 결과: Partition discovery: 0.87s (단순 구조)
</span></code></pre></div></div>

<h3 id="안티패턴-2-small-files-문제">안티패턴 #2: Small Files 문제</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 안티패턴: 시간별로 작은 파일들 생성</span>
s3://bucket/data/events/date<span class="o">=</span>2024-01-15/
  ├── <span class="nv">hour</span><span class="o">=</span>00/
  │   ├── part-00000.parquet <span class="o">(</span>2MB<span class="o">)</span>
  │   ├── part-00001.parquet <span class="o">(</span>1.5MB<span class="o">)</span>
  │   └── part-00002.parquet <span class="o">(</span>3MB<span class="o">)</span>
  ├── <span class="nv">hour</span><span class="o">=</span>01/
  │   ├── part-00000.parquet <span class="o">(</span>2.3MB<span class="o">)</span>
  │   └── part-00001.parquet <span class="o">(</span>1.8MB<span class="o">)</span>
  ...
</code></pre></div></div>

<h4 id="문제점-1"><strong>문제점</strong></h4>
<ul>
  <li><strong>GET 요청 폭증</strong>: 작은 파일마다 별도 HTTP 요청</li>
  <li><strong>I/O 오버헤드</strong>: 파일 오픈/클로즈 반복</li>
  <li><strong>메타데이터 비용</strong>: 파일 수 × 메타데이터 크기</li>
  <li><strong>쿼리 성능</strong>: Spark executor가 수많은 파일 처리</li>
</ul>

<h4 id="small-files의-영향"><strong>Small Files의 영향</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>파일 크기</strong></th>
      <th><strong>파일 수</strong></th>
      <th><strong>총 데이터</strong></th>
      <th><strong>Spark 읽기 시간</strong></th>
      <th><strong>S3 비용</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>128MB</td>
      <td>1,000개</td>
      <td>128GB</td>
      <td>45초</td>
      <td>기준</td>
    </tr>
    <tr>
      <td>10MB</td>
      <td>13,000개</td>
      <td>128GB</td>
      <td>4분 20초</td>
      <td>1.8x</td>
    </tr>
    <tr>
      <td>1MB</td>
      <td>130,000개</td>
      <td>128GB</td>
      <td>12분 35초</td>
      <td>3.2x</td>
    </tr>
  </tbody>
</table>

<h3 id="안티패턴-3-prefix-hotspot">안티패턴 #3: Prefix Hotspot</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 안티패턴: 동일 prefix에 집중</span>
s3://bucket/data/events/2024-01-15/
  ├── event-000001.parquet
  ├── event-000002.parquet
  ├── event-000003.parquet
  ...
  └── event-999999.parquet
</code></pre></div></div>

<h4 id="문제점-2"><strong>문제점</strong></h4>
<ul>
  <li><strong>Request Rate 제한</strong>: 동일 prefix로 요청 집중</li>
  <li><strong>성능 저하</strong>: 3,500/5,500 RPS 한계 도달</li>
  <li><strong>병렬 처리 제한</strong>: 분산 읽기 성능 저하</li>
</ul>

<hr />

<h2 id="s3-최적화-파티셔닝-전략">🚀 S3 최적화 파티셔닝 전략</h2>

<h3 id="전략-1-단순하고-얕은-구조">전략 #1: 단순하고 얕은 구조</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 최적화: yyyy-mm-dd 또는 yyyymmdd 단일 레벨</span>
s3://bucket/data/events/date<span class="o">=</span>2024-01-15/
  ├── part-00000-uuid.snappy.parquet <span class="o">(</span>128MB<span class="o">)</span>
  ├── part-00001-uuid.snappy.parquet <span class="o">(</span>128MB<span class="o">)</span>
  └── part-00002-uuid.snappy.parquet <span class="o">(</span>128MB<span class="o">)</span>
</code></pre></div></div>

<h4 id="장점"><strong>장점</strong></h4>
<ul>
  <li><strong>List 연산 최소화</strong>: 1-2번의 API 호출</li>
  <li><strong>빠른 파티션 탐색</strong>: 네트워크 왕복 감소</li>
  <li><strong>예측 가능한 성능</strong>: 일관된 응답 시간</li>
</ul>

<h4 id="spark-설정"><strong>Spark 설정</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spark에서 단순 파티션 구조 생성
</span><span class="n">df</span><span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># date 컬럼을 yyyy-mm-dd 형식으로 준비
</span><span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">date_format</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="nf">date_format</span><span class="p">(</span><span class="sh">"</span><span class="s">timestamp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">yyyy-MM-dd</span><span class="sh">"</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="전략-2-적절한-파일-크기-유지">전략 #2: 적절한 파일 크기 유지</h3>

<table>
  <thead>
    <tr>
      <th><strong>파일 크기</strong></th>
      <th><strong>권장 사항</strong></th>
      <th><strong>이유</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>&lt; 10MB</strong></td>
      <td>❌ 너무 작음</td>
      <td>Small files 문제</td>
    </tr>
    <tr>
      <td><strong>10-64MB</strong></td>
      <td>⚠️ 작음</td>
      <td>가능하면 더 크게</td>
    </tr>
    <tr>
      <td><strong>64-256MB</strong></td>
      <td>✅ 최적</td>
      <td>권장 범위</td>
    </tr>
    <tr>
      <td><strong>256-512MB</strong></td>
      <td>✅ 좋음</td>
      <td>대용량 처리 적합</td>
    </tr>
    <tr>
      <td><strong>&gt; 512MB</strong></td>
      <td>⚠️ 큼</td>
      <td>파일당 처리 시간 증가</td>
    </tr>
  </tbody>
</table>

<h4 id="파일-크기-최적화"><strong>파일 크기 최적화</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Spark에서 파일 크기 제어
</span><span class="n">spark</span><span class="p">.</span><span class="n">conf</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.files.maxRecordsPerFile</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">)</span>
<span class="n">spark</span><span class="p">.</span><span class="n">conf</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.files.maxPartitionBytes</span><span class="sh">"</span><span class="p">,</span> <span class="mi">134217728</span><span class="p">)</span>  <span class="c1"># 128MB
</span>
<span class="c1"># repartition으로 파일 수 조정
</span><span class="n">df</span><span class="p">.</span><span class="nf">repartition</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="compaction-작업"><strong>Compaction 작업</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Small files를 큰 파일로 병합
</span><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">S3 Compaction</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 기존 작은 파일들 읽기
</span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/date=2024-01-15/</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 적절한 파티션 수로 재작성
</span><span class="n">num_partitions</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1000000</span><span class="p">))</span>  <span class="c1"># 파티션당 100만 레코드
</span>
<span class="n">df</span><span class="p">.</span><span class="nf">repartition</span><span class="p">(</span><span class="n">num_partitions</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">overwrite</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events-compacted/date=2024-01-15/</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="전략-3-prefix-분산">전략 #3: Prefix 분산</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 최적화: Prefix를 분산하여 병렬 처리 개선</span>
s3://bucket/data/events/
  ├── <span class="nb">date</span><span class="o">=</span>2024-01-15/shard<span class="o">=</span>0/
  │   ├── part-00000.parquet
  │   └── part-00001.parquet
  ├── <span class="nb">date</span><span class="o">=</span>2024-01-15/shard<span class="o">=</span>1/
  │   ├── part-00000.parquet
  │   └── part-00001.parquet
  ...
</code></pre></div></div>

<h4 id="shard-기반-파티셔닝"><strong>Shard 기반 파티셔닝</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># hash 기반 shard 생성
</span><span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">hash</span><span class="p">,</span> <span class="nb">abs</span><span class="p">,</span> <span class="n">col</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">shard</span><span class="sh">"</span><span class="p">,</span> <span class="nf">abs</span><span class="p">(</span><span class="nf">hash</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">user_id</span><span class="sh">"</span><span class="p">)))</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">shard</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="전략-4-날짜-형식-선택">전략 #4: 날짜 형식 선택</h3>

<table>
  <thead>
    <tr>
      <th><strong>형식</strong></th>
      <th><strong>예시</strong></th>
      <th><strong>장단점</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>yyyy/mm/dd</strong></td>
      <td><code class="language-plaintext highlighter-rouge">2024/01/15</code></td>
      <td>❌ 3레벨, List 연산 많음</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd</strong></td>
      <td><code class="language-plaintext highlighter-rouge">2024-01-15</code></td>
      <td>✅ 1레벨, 가독성 좋음</td>
    </tr>
    <tr>
      <td><strong>yyyymmdd</strong></td>
      <td><code class="language-plaintext highlighter-rouge">20240115</code></td>
      <td>✅ 1레벨, 간결함</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm</strong></td>
      <td><code class="language-plaintext highlighter-rouge">2024-01</code></td>
      <td>⚠️ 월별 집계용</td>
    </tr>
  </tbody>
</table>

<h4 id="날짜-파티션-생성"><strong>날짜 파티션 생성</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">date_format</span>

<span class="c1"># yyyy-mm-dd 형식 (권장)
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="nf">date_format</span><span class="p">(</span><span class="sh">"</span><span class="s">event_time</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">yyyy-MM-dd</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># yyyymmdd 형식 (더 간결)
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="nf">date_format</span><span class="p">(</span><span class="sh">"</span><span class="s">event_time</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">yyyyMMdd</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># 파티셔닝
</span><span class="n">df</span><span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events/</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="실제-쿼리-성능-비교">📊 실제 쿼리 성능 비교</h2>

<h3 id="테스트-환경">테스트 환경</h3>

<table>
  <thead>
    <tr>
      <th><strong>항목</strong></th>
      <th><strong>설정</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>데이터 크기</strong></td>
      <td>1TB (10억 레코드)</td>
    </tr>
    <tr>
      <td><strong>기간</strong></td>
      <td>365일</td>
    </tr>
    <tr>
      <td><strong>Spark 버전</strong></td>
      <td>3.4.0</td>
    </tr>
    <tr>
      <td><strong>인스턴스</strong></td>
      <td>r5.4xlarge × 10</td>
    </tr>
    <tr>
      <td><strong>파일 형식</strong></td>
      <td>Parquet (Snappy 압축)</td>
    </tr>
  </tbody>
</table>

<h3 id="시나리오-1-단일-날짜-조회">시나리오 1: 단일 날짜 조회</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 쿼리: 특정 날짜의 데이터 조회</span>
<span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">),</span> <span class="k">AVG</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">events</span>
<span class="k">WHERE</span> <span class="nb">date</span> <span class="o">=</span> <span class="s1">'2024-01-15'</span><span class="p">;</span>
</code></pre></div></div>

<h4 id="성능-비교"><strong>성능 비교</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>파티션 구조</strong></th>
      <th><strong>파일 수</strong></th>
      <th><strong>파티션 탐색</strong></th>
      <th><strong>데이터 읽기</strong></th>
      <th><strong>총 시간</strong></th>
      <th><strong>개선율</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>yyyy/mm/dd</strong></td>
      <td>720개 (2MB)</td>
      <td>5.4초</td>
      <td>48.3초</td>
      <td><strong>53.7초</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd</strong></td>
      <td>24개 (128MB)</td>
      <td>0.9초</td>
      <td>12.1초</td>
      <td><strong>13.0초</strong></td>
      <td><strong>4.1x</strong></td>
    </tr>
    <tr>
      <td><strong>yyyymmdd</strong></td>
      <td>24개 (128MB)</td>
      <td>0.8초</td>
      <td>12.2초</td>
      <td><strong>13.0초</strong></td>
      <td><strong>4.1x</strong></td>
    </tr>
  </tbody>
</table>

<h4 id="상세-메트릭"><strong>상세 메트릭</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># yyyy/mm/dd 구조 (안티패턴)
</span><span class="p">{</span>
  <span class="sh">"</span><span class="s">partition_discovery_ms</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5430</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">s3_list_calls</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">s3_get_calls</span><span class="sh">"</span><span class="p">:</span> <span class="mi">720</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">network_latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="mi">18200</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">data_read_mb</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2880</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">executor_time_s</span><span class="sh">"</span><span class="p">:</span> <span class="mf">48.3</span>
<span class="p">}</span>

<span class="c1"># yyyy-mm-dd 구조 (최적화)
</span><span class="p">{</span>
  <span class="sh">"</span><span class="s">partition_discovery_ms</span><span class="sh">"</span><span class="p">:</span> <span class="mi">870</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">s3_list_calls</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">s3_get_calls</span><span class="sh">"</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">network_latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2400</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">data_read_mb</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3072</span><span class="p">,</span>
  <span class="sh">"</span><span class="s">executor_time_s</span><span class="sh">"</span><span class="p">:</span> <span class="mf">12.1</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="시나리오-2-7일-범위-조회">시나리오 2: 7일 범위 조회</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 쿼리: 최근 7일 데이터 분석</span>
<span class="k">SELECT</span> <span class="nb">date</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">),</span> <span class="k">SUM</span><span class="p">(</span><span class="n">amount</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">events</span>
<span class="k">WHERE</span> <span class="nb">date</span> <span class="k">BETWEEN</span> <span class="s1">'2024-01-15'</span> <span class="k">AND</span> <span class="s1">'2024-01-21'</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="nb">date</span><span class="p">;</span>
</code></pre></div></div>

<h4 id="성능-비교-1"><strong>성능 비교</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>파티션 구조</strong></th>
      <th><strong>파일 수</strong></th>
      <th><strong>파티션 탐색</strong></th>
      <th><strong>데이터 읽기</strong></th>
      <th><strong>총 시간</strong></th>
      <th><strong>개선율</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>yyyy/mm/dd</strong></td>
      <td>5,040개</td>
      <td>38.2초</td>
      <td>4분 23초</td>
      <td><strong>5분 1초</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd</strong></td>
      <td>168개</td>
      <td>6.1초</td>
      <td>1분 24초</td>
      <td><strong>1분 30초</strong></td>
      <td><strong>3.3x</strong></td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd + shard</strong></td>
      <td>168개</td>
      <td>5.9초</td>
      <td>58.2초</td>
      <td><strong>1분 4초</strong></td>
      <td><strong>4.7x</strong></td>
    </tr>
  </tbody>
</table>

<h3 id="시나리오-3-전체-테이블-스캔">시나리오 3: 전체 테이블 스캔</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- 쿼리: 전체 데이터 집계 (파티션 프루닝 없음)</span>
<span class="k">SELECT</span> <span class="n">user_id</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
<span class="k">FROM</span> <span class="n">events</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">user_id</span><span class="p">;</span>
</code></pre></div></div>

<h4 id="성능-비교-2"><strong>성능 비교</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>파티션 구조</strong></th>
      <th><strong>파일 수</strong></th>
      <th><strong>파티션 탐색</strong></th>
      <th><strong>데이터 읽기</strong></th>
      <th><strong>총 시간</strong></th>
      <th><strong>개선율</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>yyyy/mm/dd</strong></td>
      <td>262,800개</td>
      <td>6분 32초</td>
      <td>24분 18초</td>
      <td><strong>30분 50초</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd</strong></td>
      <td>8,760개</td>
      <td>1분 48초</td>
      <td>18분 52초</td>
      <td><strong>20분 40초</strong></td>
      <td><strong>1.5x</strong></td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd (compacted)</strong></td>
      <td>4,380개</td>
      <td>52.3초</td>
      <td>15분 23초</td>
      <td><strong>16분 15초</strong></td>
      <td><strong>1.9x</strong></td>
    </tr>
  </tbody>
</table>

<h3 id="athena-쿼리-비용-비교">Athena 쿼리 비용 비교</h3>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Athena에서 동일 쿼리 실행</span>
<span class="k">SELECT</span> <span class="o">*</span>
<span class="k">FROM</span> <span class="n">events</span>
<span class="k">WHERE</span> <span class="nb">date</span> <span class="o">=</span> <span class="s1">'2024-01-15'</span><span class="p">;</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th><strong>파티션 구조</strong></th>
      <th><strong>스캔 데이터</strong></th>
      <th><strong>실행 시간</strong></th>
      <th><strong>비용 (per query)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>yyyy/mm/dd</strong></td>
      <td>3.2 GB</td>
      <td>8.3초</td>
      <td>$0.016</td>
    </tr>
    <tr>
      <td><strong>yyyy-mm-dd</strong></td>
      <td>3.0 GB</td>
      <td>2.1초</td>
      <td>$0.015</td>
    </tr>
    <tr>
      <td><strong>파티션 없음</strong></td>
      <td>1,024 GB</td>
      <td>1분 34초</td>
      <td>$5.12</td>
    </tr>
  </tbody>
</table>

<p><strong>개선 효과</strong>: 파티션 최적화로 <strong>74% 비용 절감</strong> (파티션 없음 대비)</p>

<hr />

<h2 id="실무-마이그레이션-가이드">🔧 실무 마이그레이션 가이드</h2>

<h3 id="1단계-현재-상태-분석">1단계: 현재 상태 분석</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 기존 파티션 구조 분석
</span><span class="kn">import</span> <span class="n">boto3</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="nf">client</span><span class="p">(</span><span class="sh">'</span><span class="s">s3</span><span class="sh">'</span><span class="p">)</span>
<span class="n">paginator</span> <span class="o">=</span> <span class="n">s3</span><span class="p">.</span><span class="nf">get_paginator</span><span class="p">(</span><span class="sh">'</span><span class="s">list_objects_v2</span><span class="sh">'</span><span class="p">)</span>

<span class="n">bucket</span> <span class="o">=</span> <span class="sh">'</span><span class="s">my-bucket</span><span class="sh">'</span>
<span class="n">prefix</span> <span class="o">=</span> <span class="sh">'</span><span class="s">data/events/</span><span class="sh">'</span>

<span class="c1"># 파티션별 파일 수와 크기 집계
</span><span class="n">stats</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">{</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">paginator</span><span class="p">.</span><span class="nf">paginate</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span> <span class="n">Prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">page</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">Contents</span><span class="sh">'</span><span class="p">,</span> <span class="p">[]):</span>
        <span class="c1"># 파티션 추출 (예: year=2024/month=01/day=15)
</span>        <span class="n">parts</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="sh">'</span><span class="s">Key</span><span class="sh">'</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">partition</span> <span class="o">=</span> <span class="sh">'</span><span class="s">/</span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">parts</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="n">stats</span><span class="p">[</span><span class="n">partition</span><span class="p">][</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">stats</span><span class="p">[</span><span class="n">partition</span><span class="p">][</span><span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">]</span> <span class="o">+=</span> <span class="n">obj</span><span class="p">[</span><span class="sh">'</span><span class="s">Size</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># 통계 출력
</span><span class="k">for</span> <span class="n">partition</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">stats</span><span class="p">.</span><span class="nf">items</span><span class="p">()):</span>
    <span class="n">avg_size_mb</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">size</span><span class="sh">"</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">[</span><span class="sh">"</span><span class="s">count</span><span class="sh">"</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">partition</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s"> files, avg </span><span class="si">{</span><span class="n">avg_size_mb</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">MB</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="분석-결과-예시"><strong>분석 결과 예시</strong></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>year=2024/month=01/day=15: 720 files, avg 2.3MB  ❌ Small files 문제
year=2024/month=01/day=16: 680 files, avg 2.5MB  ❌
year=2024/month=01/day=17: 740 files, avg 2.1MB  ❌

권장: 128MB 파일로 consolidation 필요
</code></pre></div></div>

<h3 id="2단계-마이그레이션-계획">2단계: 마이그레이션 계획</h3>

<table>
  <thead>
    <tr>
      <th><strong>작업</strong></th>
      <th><strong>소요 시간</strong></th>
      <th><strong>다운타임</strong></th>
      <th><strong>우선순위</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>파티션 구조 재설계</strong></td>
      <td>1-2주</td>
      <td>없음</td>
      <td>높음</td>
    </tr>
    <tr>
      <td><strong>Compaction 작업</strong></td>
      <td>데이터 양에 따라</td>
      <td>없음</td>
      <td>높음</td>
    </tr>
    <tr>
      <td><strong>병렬 마이그레이션</strong></td>
      <td>3-4주</td>
      <td>없음</td>
      <td>중간</td>
    </tr>
    <tr>
      <td><strong>쿼리/애플리케이션 수정</strong></td>
      <td>2-3주</td>
      <td>계획된 배포</td>
      <td>높음</td>
    </tr>
    <tr>
      <td><strong>검증 및 모니터링</strong></td>
      <td>1-2주</td>
      <td>없음</td>
      <td>높음</td>
    </tr>
  </tbody>
</table>

<h3 id="3단계-마이그레이션-스크립트">3단계: 마이그레이션 스크립트</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">date_format</span><span class="p">,</span> <span class="nb">abs</span><span class="p">,</span> <span class="nb">hash</span><span class="p">,</span> <span class="n">col</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span> \
    <span class="p">.</span><span class="nf">appName</span><span class="p">(</span><span class="sh">"</span><span class="s">S3 Partition Migration</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">config</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.sources.partitionOverwriteMode</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">dynamic</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">getOrCreate</span><span class="p">()</span>

<span class="c1"># 기존 데이터 읽기
</span><span class="n">source_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">s3://bucket/data/events-old/year=*/month=*/day=*/</span><span class="sh">"</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>

<span class="c1"># 새로운 date 컬럼 생성
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="nf">date_format</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">event_time</span><span class="sh">"</span><span class="p">),</span> <span class="sh">"</span><span class="s">yyyy-MM-dd</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># Shard 추가 (선택사항)
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">shard</span><span class="sh">"</span><span class="p">,</span> <span class="nf">abs</span><span class="p">(</span><span class="nf">hash</span><span class="p">(</span><span class="nf">col</span><span class="p">(</span><span class="sh">"</span><span class="s">user_id</span><span class="sh">"</span><span class="p">)))</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># 파일 크기 최적화
</span><span class="n">spark</span><span class="p">.</span><span class="n">conf</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="sh">"</span><span class="s">spark.sql.files.maxPartitionBytes</span><span class="sh">"</span><span class="p">,</span> <span class="mi">134217728</span><span class="p">)</span>  <span class="c1"># 128MB
</span>
<span class="c1"># 적절한 파티션 수 계산
</span><span class="n">total_size_gb</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span> <span class="o">*</span> <span class="mi">500</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span>  <span class="c1"># 레코드당 ~500 bytes
</span><span class="n">num_partitions</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">total_size_gb</span> <span class="o">*</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># 128MB 파일 기준
</span>
<span class="c1"># 새로운 구조로 저장
</span><span class="n">df</span><span class="p">.</span><span class="nf">repartition</span><span class="p">(</span><span class="n">num_partitions</span><span class="p">,</span> <span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">write</span> \
    <span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">overwrite</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">partitionBy</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://bucket/data/events-new/</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="4단계-점진적-마이그레이션">4단계: 점진적 마이그레이션</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 날짜별로 점진적 마이그레이션
</span><span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="n">start_date</span> <span class="o">=</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
<span class="n">current_date</span> <span class="o">=</span> <span class="n">start_date</span>

<span class="k">while</span> <span class="n">current_date</span> <span class="o">&lt;=</span> <span class="n">end_date</span><span class="p">:</span>
    <span class="n">year</span> <span class="o">=</span> <span class="n">current_date</span><span class="p">.</span><span class="n">year</span>
    <span class="n">month</span> <span class="o">=</span> <span class="n">current_date</span><span class="p">.</span><span class="n">month</span>
    <span class="n">day</span> <span class="o">=</span> <span class="n">current_date</span><span class="p">.</span><span class="n">day</span>
    <span class="n">date_str</span> <span class="o">=</span> <span class="n">current_date</span><span class="p">.</span><span class="nf">strftime</span><span class="p">(</span><span class="sh">"</span><span class="s">%Y-%m-%d</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Processing </span><span class="si">{</span><span class="n">date_str</span><span class="si">}</span><span class="s">...</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># 특정 날짜 데이터 읽기
</span>    <span class="n">old_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">s3://bucket/data/events-old/year=</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s">/month=</span><span class="si">{</span><span class="n">month</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/day=</span><span class="si">{</span><span class="n">day</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="sh">"</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="n">old_path</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">withColumn</span><span class="p">(</span><span class="sh">"</span><span class="s">date</span><span class="sh">"</span><span class="p">,</span> <span class="nf">lit</span><span class="p">(</span><span class="n">date_str</span><span class="p">))</span>
        
        <span class="c1"># 파일 크기 최적화
</span>        <span class="n">num_files</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1000000</span><span class="p">))</span>  <span class="c1"># 파일당 100만 레코드
</span>        
        <span class="n">df</span><span class="p">.</span><span class="nf">repartition</span><span class="p">(</span><span class="n">num_files</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">write</span> \
            <span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="sh">"</span><span class="s">overwrite</span><span class="sh">"</span><span class="p">)</span> \
            <span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">s3://bucket/data/events-new/date=</span><span class="si">{</span><span class="n">date_str</span><span class="si">}</span><span class="s">/</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✓ </span><span class="si">{</span><span class="n">date_str</span><span class="si">}</span><span class="s"> completed</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✗ </span><span class="si">{</span><span class="n">date_str</span><span class="si">}</span><span class="s"> failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="n">current_date</span> <span class="o">+=</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="5단계-검증">5단계: 검증</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 마이그레이션 검증 스크립트
</span><span class="k">def</span> <span class="nf">validate_migration</span><span class="p">(</span><span class="n">old_path</span><span class="p">,</span> <span class="n">new_path</span><span class="p">,</span> <span class="n">date</span><span class="p">):</span>
    <span class="c1"># 레코드 수 비교
</span>    <span class="n">old_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">old_path</span><span class="si">}</span><span class="s">/year=</span><span class="si">{</span><span class="n">date</span><span class="p">.</span><span class="n">year</span><span class="si">}</span><span class="s">/month=</span><span class="si">{</span><span class="n">date</span><span class="p">.</span><span class="n">month</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/day=</span><span class="si">{</span><span class="n">date</span><span class="p">.</span><span class="n">day</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">new_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">parquet</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">new_path</span><span class="si">}</span><span class="s">/date=</span><span class="si">{</span><span class="n">date</span><span class="p">.</span><span class="nf">strftime</span><span class="p">(</span><span class="sh">'</span><span class="s">%Y-%m-%d</span><span class="sh">'</span><span class="p">)</span><span class="si">}</span><span class="s">/</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="n">old_count</span> <span class="o">=</span> <span class="n">old_df</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span>
    <span class="n">new_count</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="nf">count</span><span class="p">()</span>
    
    <span class="c1"># 체크섬 비교 (샘플링)
</span>    <span class="n">old_checksum</span> <span class="o">=</span> <span class="n">old_df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mf">0.01</span><span class="p">).</span><span class="nf">selectExpr</span><span class="p">(</span><span class="sh">"</span><span class="s">sum(hash(*))</span><span class="sh">"</span><span class="p">).</span><span class="nf">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">new_checksum</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mf">0.01</span><span class="p">).</span><span class="nf">selectExpr</span><span class="p">(</span><span class="sh">"</span><span class="s">sum(hash(*))</span><span class="sh">"</span><span class="p">).</span><span class="nf">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># 결과
</span>    <span class="k">if</span> <span class="n">old_count</span> <span class="o">==</span> <span class="n">new_count</span> <span class="ow">and</span> <span class="n">old_checksum</span> <span class="o">==</span> <span class="n">new_checksum</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✓ </span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s">: Valid (</span><span class="si">{</span><span class="n">old_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> records)</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✗ </span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s">: Invalid (old: </span><span class="si">{</span><span class="n">old_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">, new: </span><span class="si">{</span><span class="n">new_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">False</span>

<span class="c1"># 전체 기간 검증
</span><span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="n">start_date</span> <span class="o">=</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
<span class="n">current_date</span> <span class="o">=</span> <span class="n">start_date</span>

<span class="k">while</span> <span class="n">current_date</span> <span class="o">&lt;=</span> <span class="n">end_date</span><span class="p">:</span>
    <span class="nf">validate_migration</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">s3://bucket/data/events-old</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">s3://bucket/data/events-new</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">current_date</span>
    <span class="p">)</span>
    <span class="n">current_date</span> <span class="o">+=</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="6단계-쿼리-성능-모니터링">6단계: 쿼리 성능 모니터링</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># CloudWatch 메트릭 수집
</span><span class="kn">import</span> <span class="n">boto3</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="n">cloudwatch</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="nf">client</span><span class="p">(</span><span class="sh">'</span><span class="s">cloudwatch</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Athena 쿼리 실행 시간 모니터링
</span><span class="n">response</span> <span class="o">=</span> <span class="n">cloudwatch</span><span class="p">.</span><span class="nf">get_metric_statistics</span><span class="p">(</span>
    <span class="n">Namespace</span><span class="o">=</span><span class="sh">'</span><span class="s">AWS/Athena</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">MetricName</span><span class="o">=</span><span class="sh">'</span><span class="s">EngineExecutionTime</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">Dimensions</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">WorkGroup</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Value</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">primary</span><span class="sh">'</span><span class="p">}</span>
    <span class="p">],</span>
    <span class="n">StartTime</span><span class="o">=</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span> <span class="o">-</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">7</span><span class="p">),</span>
    <span class="n">EndTime</span><span class="o">=</span><span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">(),</span>
    <span class="n">Period</span><span class="o">=</span><span class="mi">3600</span><span class="p">,</span>
    <span class="n">Statistics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Average</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Maximum</span><span class="sh">'</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 결과 분석
</span><span class="k">for</span> <span class="n">datapoint</span> <span class="ow">in</span> <span class="n">response</span><span class="p">[</span><span class="sh">'</span><span class="s">Datapoints</span><span class="sh">'</span><span class="p">]:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">datapoint</span><span class="p">[</span><span class="sh">'</span><span class="s">Timestamp</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">: </span><span class="sh">"</span>
          <span class="sa">f</span><span class="sh">"</span><span class="s">Avg=</span><span class="si">{</span><span class="n">datapoint</span><span class="p">[</span><span class="sh">'</span><span class="s">Average</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s, </span><span class="sh">"</span>
          <span class="sa">f</span><span class="sh">"</span><span class="s">Max=</span><span class="si">{</span><span class="n">datapoint</span><span class="p">[</span><span class="sh">'</span><span class="s">Maximum</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="7단계-비용-최적화">7단계: 비용 최적화</h3>

<h4 id="s3-storage-class-전환"><strong>S3 Storage Class 전환</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 오래된 파티션을 Intelligent-Tiering으로 전환
</span><span class="kn">import</span> <span class="n">boto3</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="nf">client</span><span class="p">(</span><span class="sh">'</span><span class="s">s3</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">transition_old_partitions</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">days_old</span><span class="o">=</span><span class="mi">90</span><span class="p">):</span>
    <span class="n">cutoff_date</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">()</span> <span class="o">-</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="n">days_old</span><span class="p">)</span>
    
    <span class="c1"># Lifecycle policy 생성
</span>    <span class="n">lifecycle_config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">Rules</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="sh">'</span><span class="s">Id</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">TransitionOldData</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Status</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Enabled</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Prefix</span><span class="sh">'</span><span class="p">:</span> <span class="n">prefix</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">Transitions</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span>
                        <span class="sh">'</span><span class="s">Days</span><span class="sh">'</span><span class="p">:</span> <span class="n">days_old</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">StorageClass</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">INTELLIGENT_TIERING</span><span class="sh">'</span>
                    <span class="p">}</span>
                <span class="p">]</span>
            <span class="p">}</span>
        <span class="p">]</span>
    <span class="p">}</span>
    
    <span class="n">s3</span><span class="p">.</span><span class="nf">put_bucket_lifecycle_configuration</span><span class="p">(</span>
        <span class="n">Bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span>
        <span class="n">LifecycleConfiguration</span><span class="o">=</span><span class="n">lifecycle_config</span>
    <span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✓ Lifecycle policy applied: </span><span class="si">{</span><span class="n">days_old</span><span class="si">}</span><span class="s">+ days → INTELLIGENT_TIERING</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">transition_old_partitions</span><span class="p">(</span><span class="sh">'</span><span class="s">my-bucket</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">data/events/</span><span class="sh">'</span><span class="p">,</span> <span class="mi">90</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="비용-절감-효과"><strong>비용 절감 효과</strong></h4>

<table>
  <thead>
    <tr>
      <th><strong>항목</strong></th>
      <th><strong>마이그레이션 전</strong></th>
      <th><strong>마이그레이션 후</strong></th>
      <th><strong>절감률</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>S3 Storage</strong></td>
      <td>$23,040/월 (1TB, Standard)</td>
      <td>$20,736/월 (Intelligent-Tiering)</td>
      <td>10%</td>
    </tr>
    <tr>
      <td><strong>S3 API 비용</strong></td>
      <td>$1,200/월 (LIST/GET)</td>
      <td>$360/월</td>
      <td>70%</td>
    </tr>
    <tr>
      <td><strong>Athena 스캔</strong></td>
      <td>$512/월</td>
      <td>$128/월</td>
      <td>75%</td>
    </tr>
    <tr>
      <td><strong>Spark 컴퓨팅</strong></td>
      <td>$4,800/월</td>
      <td>$3,200/월</td>
      <td>33%</td>
    </tr>
    <tr>
      <td><strong>총 비용</strong></td>
      <td><strong>$29,552/월</strong></td>
      <td><strong>$24,424/월</strong></td>
      <td><strong>17%</strong></td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="학습-요약">📚 학습 요약</h2>

<h3 id="핵심-포인트">핵심 포인트</h3>

<ol>
  <li><strong>아키텍처 이해가 핵심</strong>
    <ul>
      <li>HDFS: 계층적 파일 시스템, NameNode 메타데이터</li>
      <li>S3: Flat namespace 객체 스토리지, List 연산 비용</li>
    </ul>
  </li>
  <li><strong>S3 최적화 전략</strong>
    <ul>
      <li><strong>얕은 구조</strong>: yyyy-mm-dd 단일 레벨</li>
      <li><strong>큰 파일</strong>: 64-256MB 권장</li>
      <li><strong>Prefix 분산</strong>: Request rate 제한 회피</li>
    </ul>
  </li>
  <li><strong>성능 개선 효과</strong>
    <ul>
      <li><strong>단일 날짜 조회</strong>: 4.1x 빠름</li>
      <li><strong>7일 범위 조회</strong>: 4.7x 빠름 (shard 사용)</li>
      <li><strong>비용 절감</strong>: 17% 절감</li>
    </ul>
  </li>
  <li><strong>마이그레이션 모범 사례</strong>
    <ul>
      <li>점진적 마이그레이션</li>
      <li>철저한 검증</li>
      <li>성능 모니터링</li>
    </ul>
  </li>
</ol>

<h3 id="실무-체크리스트">실무 체크리스트</h3>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />현재 파티션 구조 분석 완료</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Small files 문제 파악</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />마이그레이션 계획 수립</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Compaction 스크립트 준비</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />검증 프로세스 정의</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />쿼리/애플리케이션 수정</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />성능 모니터링 대시보드 구축</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />비용 최적화 적용</li>
</ul>

<h3 id="추가-학습-자료">추가 학습 자료</h3>

<ul>
  <li><strong>AWS 공식 문서</strong>: S3 Performance Best Practices</li>
  <li><strong>Spark 최적화</strong>: Adaptive Query Execution (AQE)</li>
  <li><strong>Parquet 최적화</strong>: Row Group 크기, Compression</li>
  <li><strong>Iceberg/Delta Lake</strong>: 테이블 포맷으로 파티셔닝 추상화</li>
</ul>

<hr />

<blockquote>
  <p><strong>“올바른 파티셔닝 전략은 단순히 성능 향상이 아닌, 비용 절감과 운영 효율성까지 개선합니다.”</strong></p>
</blockquote>

<p>HDFS에서 S3로의 전환은 단순한 스토리지 마이그레이션이 아닙니다. 아키텍처의 근본적인 차이를 이해하고 그에 맞는 최적화 전략을 적용할 때, 진정한 클라우드 네이티브 데이터 레이크의 가치를 실현할 수 있습니다.</p>

  </div>

  
  <div class="post-navigation">
    <div class="nav-links">
      
      
      
        
          
          
      
      
      
      
    </div>
    
    <div class="series-overview">
      <a href="/categories/data-engineering/" class="btn btn-secondary">
        📚 시리즈 전체 보기
      </a>
    </div>
  </div>
  
</article>

    </div>
  </main>
  
  
  <footer class="site-footer">
  <div class="container">
    <div class="footer-content">
      <div class="footer-section">
        <h3>Data Droid Blog</h3>
        <p>데이터 엔지니어가 다루는 기술 블로그</p>
      </div>
      
      <div class="footer-section">
        <h4>카테고리</h4>
        <ul>
          <li><a href="/categories/data-engineering/">데이터 엔지니어링</a></li>
          <li><a href="/categories/bi-engineering/">BI 엔지니어링</a></li>
          <li><a href="/categories/infrastructure-tools/">인프라 & 도구</a></li>
          <li><a href="/categories/data-quality/">데이터 품질</a></li>
          <li><a href="/categories/data-ai/">Data AI</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>링크</h4>
        <ul>
          <li><a href="/">홈</a></li>
          <li><a href="/blog/">블로그</a></li>
          <li><a href="/about/">소개</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>소셜</h4>
        <ul>
          
          <li><a href="https://github.com/data-droid">GitHub</a></li>
          
          <li><a href="https://www.linkedin.com/in/jaekyung-lee-a61ab2193/">LinkedIn</a></li>
        </ul>
      </div>
    </div>
    
    <div class="footer-bottom">
      <p>&copy; 2025 Data Droid Blog. 모든 권리 보유</p>
    </div>
  </div>
</footer>



  
  <script src="/assets/js/main.js"></script>
</body>
</html>
