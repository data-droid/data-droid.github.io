<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="stylesheet" href="/assets/css/style.css">
  <!-- Head includes for Jekyll -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- SEO -->

<meta name="description" content="Explore state-of-the-art transformer-based time series forecasting models including Informer, Autoformer, FEDformer, and PatchTST with hands-on practice.">



<title>Part 3: Transformer-Based Time Series Forecasting Models - Data Droid Blog</title>


<!-- Open Graph -->
<meta property="og:title" content="Part 3: Transformer-Based Time Series Forecasting Models">
<meta property="og:description" content="Explore state-of-the-art transformer-based time series forecasting models including Informer, Autoformer, FEDformer, and PatchTST with hands-on practice.">
<meta property="og:url" content="http://localhost:4000/en_posts/2025-09-06-time-series-transformers.html">
<meta property="og:type" content="website">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Part 3: Transformer-Based Time Series Forecasting Models">
<meta name="twitter:description" content="Explore state-of-the-art transformer-based time series forecasting models including Informer, Autoformer, FEDformer, and PatchTST with hands-on practice.">

<!-- Favicon -->
<link rel="icon" type="image/svg+xml" href="/assets/favicon.svg">
<link rel="icon" type="image/x-icon" href="/favicon.ico">

<!-- RSS Feed -->
<link rel="alternate" type="application/rss+xml" title="Data Droid Blog" href="/feed.xml">

<!-- Google Analytics -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GP9LT745PP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GP9LT745PP');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <div class="site-title">
      <a href="/">Data Droid Blog</a>
    </div>
    
    <!-- Mobile menu toggle button -->
    <button class="mobile-menu-toggle" aria-label="Î©îÎâ¥ Ïó¥Í∏∞/Îã´Í∏∞">
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
    </button>
    
    <nav class="site-nav">
      <ul class="nav-list">
        <li><a href="/">Home</a></li>
                  <li class="dropdown">
            <a href="#" class="dropdown-toggle">Categories</a>
            <ul class="dropdown-menu">

              <li><a href="/en/categories/data-engineering/">Data Engineering</a></li>
              <li><a href="/en/categories/bi-engineering/">BI Engineering</a></li>
              <li><a href="/en/categories/infrastructure-tools/">Infrastructure & Tools</a></li>
              <li><a href="/en/categories/data-quality/">Data Quality</a></li>
              <li><a href="/en/categories/data-ai/">Data AI</a></li>
            </ul>
          </li>
        <li><a href="/en/blog/">Blog</a></li>
        <li><a href="/en/about/">About</a></li>
      </ul>
    </nav>
    
    <div class="language-switcher">
      
        <!-- Ìè¨Ïä§Ìä∏Ïö© Ïñ∏Ïñ¥ Ï†ÑÌôò -->
        
          
          <a href="/data-ai/2025/09/06/time-series-transformers.html" class="lang-btn">ÌïúÍµ≠Ïñ¥</a>
          <a href="/en_posts/2025-09-06-time-series-transformers.html" class="lang-btn active">English</a>
        
      
    </div>
  </div>
</header>

  
  <main class="site-main">
    <div class="container">
      <article class="post">
  <header class="post-header">
    <div class="post-meta">
      <span class="post-category">Data ai</span>
      <span class="post-date">2025ÎÖÑ 09Ïõî 06Ïùº</span>
      <span class="post-author">Data Droid</span>
    </div>
    
    <h1 class="post-title">Part 3: Transformer-Based Time Series Forecasting Models</h1>
    
    
    <div class="post-tags">
      
        <span class="tag">time-series-forecasting</span>
      
        <span class="tag">transformer</span>
      
        <span class="tag">Informer</span>
      
        <span class="tag">Autoformer</span>
      
        <span class="tag">FEDformer</span>
      
        <span class="tag">PatchTST</span>
      
        <span class="tag">deep-learning</span>
      
        <span class="tag">AI</span>
      
    </div>
    
    
    
    <div class="post-series">
      <span class="series-badge">üìö Time series forecasting ÏãúÎ¶¨Ï¶à</span>
      <span class="series-order">Part 4</span>
    </div>
    
    
    
    <div class="post-info">
      
        <span class="reading-time">‚è±Ô∏è 15</span>
      
      
        <span class="difficulty">üìä intermediate</span>
      
    </div>
    
  </header>

  <div class="post-content">
    <h1 id="part-3-transformer-based-time-series-forecasting-models">Part 3: Transformer-Based Time Series Forecasting Models</h1>

<p>Welcome to the third part of our time series forecasting series! In this installment, we‚Äôll explore how the revolutionary Transformer architecture, which transformed natural language processing, has been adapted for time series forecasting.</p>

<h2 id="-learning-objectives">üìö Learning Objectives</h2>

<p>By the end of this part, you will learn:</p>

<ul>
  <li>The background and necessity of applying Transformers to time series forecasting</li>
  <li>Key characteristics of major models: Informer, Autoformer, FEDformer, PatchTST</li>
  <li>Strengths and weaknesses of each model and their application domains</li>
  <li>Hands-on practice with transformer-based time series forecasting using real data</li>
</ul>

<h2 id="-background-why-transformers-for-time-series">üîç Background: Why Transformers for Time Series?</h2>

<h3 id="limitations-of-previous-methods">Limitations of Previous Methods</h3>

<p><strong>RNN/LSTM Problems:</strong></p>
<ul>
  <li>Sequential processing leading to long training times</li>
  <li>Difficulty learning long-term dependencies</li>
  <li>Inability to parallelize processing</li>
</ul>

<p><strong>CNN Limitations:</strong></p>
<ul>
  <li>Focus only on local patterns</li>
  <li>Difficulty capturing long-range dependencies</li>
</ul>

<h3 id="transformer-advantages">Transformer Advantages</h3>

<ol>
  <li><strong>Parallel Processing</strong>: Process all time points simultaneously</li>
  <li><strong>Long-range Dependencies</strong>: Learn relationships in long sequences through self-attention</li>
  <li><strong>Scalability</strong>: Performance improvement with larger models and datasets</li>
</ol>

<h2 id="-major-transformer-based-time-series-models">üöÄ Major Transformer-Based Time Series Models</h2>

<h3 id="1-informer-2021">1. Informer (2021)</h3>

<p><strong>Core Ideas:</strong></p>
<ul>
  <li>ProbSparse Self-attention reduces complexity from O(L¬≤) to O(L log L)</li>
  <li>Self-attention Distilling compresses information across layers</li>
  <li>Generative Decoder predicts long sequences at once</li>
</ul>

<p><strong>Key Features:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Informer's core structure
</span><span class="k">class</span> <span class="nc">Informer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">enc_in</span><span class="p">,</span> <span class="n">dec_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">label_len</span><span class="p">,</span> <span class="n">out_len</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Informer</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">enc_in</span> <span class="o">=</span> <span class="n">enc_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dec_in</span> <span class="o">=</span> <span class="n">dec_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">c_out</span> <span class="o">=</span> <span class="n">c_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="n">self</span><span class="p">.</span><span class="n">label_len</span> <span class="o">=</span> <span class="n">label_len</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_len</span> <span class="o">=</span> <span class="n">out_len</span>
        
        <span class="c1"># Uses ProbSparse Attention
</span>        <span class="n">self</span><span class="p">.</span><span class="n">attn</span> <span class="o">=</span> <span class="nc">ProbAttention</span><span class="p">(</span><span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        
        <span class="c1"># Encoder and Decoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nc">Encoder</span><span class="p">(...)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="nc">Decoder</span><span class="p">(...)</span>
</code></pre></div></div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Efficient on long sequences</li>
  <li>Excellent performance across diverse datasets</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Long training time due to complex structure</li>
  <li>Difficult hyperparameter tuning</li>
</ul>

<h3 id="2-autoformer-2021">2. Autoformer (2021)</h3>

<p><strong>Core Ideas:</strong></p>
<ul>
  <li>Auto-Correlation mechanism automatically learns periodicity in time series</li>
  <li>Decomposition Block separates trend and seasonality</li>
  <li>Series-wise Connection minimizes information loss</li>
</ul>

<p><strong>Key Features:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Autoformer's Auto-Correlation
</span><span class="k">class</span> <span class="nc">AutoCorrelation</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="c1"># Calculate correlation to find periodicity in time series
</span>        <span class="n">autocorr</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">autocorrelation</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">value_projection</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">*</span> <span class="n">autocorr</span>
</code></pre></div></div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Automatic learning of time series periodicity</li>
  <li>Improved interpretability through trend and seasonality decomposition</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Limited performance on data without periodicity</li>
  <li>Difficulty learning complex patterns</li>
</ul>

<h3 id="3-fedformer-2022">3. FEDformer (2022)</h3>

<p><strong>Core Ideas:</strong></p>
<ul>
  <li>Fourier Enhanced Decomposed Transformer</li>
  <li>Attention in frequency domain using FFT</li>
  <li>Model ensemble for performance improvement</li>
</ul>

<p><strong>Key Features:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># FEDformer's Fourier Attention
</span><span class="k">class</span> <span class="nc">FourierAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Transform to frequency domain using FFT
</span>        <span class="n">x_freq</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="nf">rfft</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Calculate attention in frequency domain
</span>        <span class="n">attn_freq</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">frequency_attention</span><span class="p">(</span><span class="n">x_freq</span><span class="p">)</span>
        <span class="c1"># Inverse transform back to time domain
</span>        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="nf">irfft</span><span class="p">(</span><span class="n">attn_freq</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Efficient processing in frequency domain</li>
  <li>Can learn various periodic patterns</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>FFT computation cost</li>
  <li>May not be suitable for real-time prediction</li>
</ul>

<h3 id="4-patchtst-2023">4. PatchTST (2023)</h3>

<p><strong>Core Ideas:</strong></p>
<ul>
  <li>Process time series in patch units</li>
  <li>Channel Independence for multivariate time series</li>
  <li>Simple structure with excellent performance</li>
</ul>

<p><strong>Key Features:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PatchTST's patch creation
</span><span class="k">def</span> <span class="nf">create_patch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">patch_len</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="c1"># Split time series into patches
</span>    <span class="n">patches</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">unfold</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">patch_len</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">stride</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">patches</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Simple and efficient structure</li>
  <li>Excellent performance on multivariate time series</li>
  <li>Fast training and inference</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>Sensitive to patch size</li>
  <li>Limited on very long sequences</li>
</ul>

<h2 id="Ô∏è-hands-on-practice-stock-price-prediction-with-patchtst">üõ†Ô∏è Hands-on Practice: Stock Price Prediction with PatchTST</h2>

<p>Now let‚Äôs implement a PatchTST model using real data.</p>

<h3 id="1-data-preparation">1. Data Preparation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="c1"># Generate stock data (use yfinance for real data)
</span><span class="k">def</span> <span class="nf">generate_stock_data</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Generate synthetic stock data</span><span class="sh">"""</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># Generate data with trend and seasonality
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="n">trend</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">t</span>
    <span class="n">seasonal</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    
    <span class="c1"># Generate multivariate time series
</span>    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
        <span class="n">data</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">trend</span> <span class="o">+</span> <span class="n">seasonal</span> <span class="o">+</span> <span class="n">noise</span> <span class="o">+</span> <span class="n">i</span><span class="o">*</span><span class="mf">0.1</span>
    
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">stock_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">)])</span>

<span class="c1"># Generate data
</span><span class="n">data</span> <span class="o">=</span> <span class="nf">generate_stock_data</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Data shape: </span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
</code></pre></div></div>

<h3 id="2-patchtst-model-implementation">2. PatchTST Model Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PatchTST</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">pred_len</span><span class="p">,</span> <span class="n">patch_len</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">PatchTST</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pred_len</span> <span class="o">=</span> <span class="n">pred_len</span>
        <span class="n">self</span><span class="p">.</span><span class="n">patch_len</span> <span class="o">=</span> <span class="n">patch_len</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="n">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        
        <span class="c1"># Calculate number of patches
</span>        <span class="n">self</span><span class="p">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">seq_len</span> <span class="o">-</span> <span class="n">patch_len</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="c1"># Input projection
</span>        <span class="n">self</span><span class="p">.</span><span class="n">input_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">patch_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
        <span class="c1"># Positional encoding
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
        
        <span class="c1"># Transformer encoder
</span>        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> 
            <span class="n">nhead</span><span class="o">=</span><span class="n">n_heads</span><span class="p">,</span> 
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">d_model</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">)</span>
        
        <span class="c1"># Output projection
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">pred_len</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">create_patches</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Split time series into patches</span><span class="sh">"""</span>
        <span class="c1"># x: (batch_size, n_features, seq_len)
</span>        <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        
        <span class="c1"># Create patches for each feature
</span>        <span class="n">patches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">feature_patches</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:].</span><span class="nf">unfold</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">patch_len</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">)</span>
            <span class="n">patches</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">feature_patches</span><span class="p">)</span>
        
        <span class="c1"># (batch_size, n_features, num_patches, patch_len)
</span>        <span class="n">patches</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">patches</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch_size, n_features, seq_len)
</span>        <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        
        <span class="c1"># Create patches
</span>        <span class="n">patches</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">create_patches</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, n_features, num_patches, patch_len)
</span>        
        <span class="c1"># Process each feature independently (Channel Independence)
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">feature_patches</span> <span class="o">=</span> <span class="n">patches</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, num_patches, patch_len)
</span>            
            <span class="c1"># Input projection
</span>            <span class="n">projected</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">input_projection</span><span class="p">(</span><span class="n">feature_patches</span><span class="p">)</span>  <span class="c1"># (batch_size, num_patches, d_model)
</span>            
            <span class="c1"># Add positional encoding
</span>            <span class="n">projected</span> <span class="o">=</span> <span class="n">projected</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">pos_encoding</span>
            
            <span class="c1"># Transformer encoder
</span>            <span class="n">encoded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transformer</span><span class="p">(</span><span class="n">projected</span><span class="p">)</span>  <span class="c1"># (batch_size, num_patches, d_model)
</span>            
            <span class="c1"># Global average pooling
</span>            <span class="n">pooled</span> <span class="o">=</span> <span class="n">encoded</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, d_model)
</span>            
            <span class="c1"># Output projection
</span>            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_projection</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>  <span class="c1"># (batch_size, pred_len)
</span>            <span class="n">outputs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        
        <span class="c1"># Combine outputs from all features
</span>        <span class="n">final_output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, n_features, pred_len)
</span>        <span class="k">return</span> <span class="n">final_output</span>

<span class="c1"># Model parameters
</span><span class="n">seq_len</span> <span class="o">=</span> <span class="mi">96</span>      <span class="c1"># Input sequence length
</span><span class="n">pred_len</span> <span class="o">=</span> <span class="mi">24</span>     <span class="c1"># Prediction length
</span><span class="n">patch_len</span> <span class="o">=</span> <span class="mi">16</span>    <span class="c1"># Patch length
</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">8</span>        <span class="c1"># Stride
</span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>    <span class="c1"># Number of features
</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">PatchTST</span><span class="p">(</span>
    <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
    <span class="n">pred_len</span><span class="o">=</span><span class="n">pred_len</span><span class="p">,</span>
    <span class="n">patch_len</span><span class="o">=</span><span class="n">patch_len</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model parameters: </span><span class="si">{</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-data-preprocessing-and-training">3. Data Preprocessing and Training</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">pred_len</span><span class="p">,</span> <span class="n">train_ratio</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">val_ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Prepare data for training</span><span class="sh">"""</span>
    <span class="c1"># Normalization
</span>    <span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
    <span class="n">scaled_data</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    
    <span class="c1"># Create sequences
</span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_len</span> <span class="o">-</span> <span class="n">pred_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">])</span>
        <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="o">+</span><span class="n">pred_len</span><span class="p">])</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># Train/validation/test split
</span>    <span class="n">n_train</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)</span>
    <span class="n">n_val</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">val_ratio</span><span class="p">)</span>
    
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
    <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="p">:</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">]</span>
    <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">n_train</span><span class="o">+</span><span class="n">n_val</span><span class="p">:]</span>
    
    <span class="nf">return </span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">scaler</span>

<span class="c1"># Prepare data
</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">scaler</span> <span class="o">=</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">pred_len</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train data: </span><span class="si">{</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Validation data: </span><span class="si">{</span><span class="n">X_val</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">y_val</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Test data: </span><span class="si">{</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Create DataLoader
</span><span class="k">def</span> <span class="nf">create_dataloader</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch, features, seq_len)
</span>    <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch, features, pred_len)
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="nf">create_dataloader</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="nf">create_dataloader</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="4-model-training">4. Model Training</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Train the model</span><span class="sh">"""</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Training
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_X</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        
        <span class="c1"># Validation
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_X</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        
        <span class="n">train_loss</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
        
        <span class="n">train_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">val_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        
        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">3</span><span class="n">d</span><span class="si">}</span><span class="s">: Train Loss = </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="s">, Val Loss = </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span>

<span class="c1"># Train model
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Starting model training...</span><span class="sh">"</span><span class="p">)</span>
<span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training completed!</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="5-results-visualization">5. Results Visualization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Visualize results</span><span class="sh">"""</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="k">break</span>
                
            <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_X</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
            
            <span class="c1"># Visualize only the first sample
</span>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">batch_X</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="n">T</span>  <span class="c1"># (seq_len, n_features)
</span>            <span class="n">y_true</span> <span class="o">=</span> <span class="n">batch_y</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="n">T</span>    <span class="c1"># (pred_len, n_features)
</span>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="n">T</span> <span class="c1"># (pred_len, n_features)
</span>            
            <span class="c1"># Inverse normalization
</span>            <span class="n">X_sample</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">X_sample</span><span class="p">)</span>
            <span class="n">y_true</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
            
            <span class="c1"># Visualization
</span>            <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span>
            
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)):</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                
                <span class="c1"># Historical data
</span>                <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">),</span> <span class="n">X_sample</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="sh">'</span><span class="s">b-</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Past</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                
                <span class="c1"># Actual future
</span>                <span class="n">future_x</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">+</span> <span class="n">pred_len</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">future_x</span><span class="p">,</span> <span class="n">y_true</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="sh">'</span><span class="s">g-</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Actual</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                
                <span class="c1"># Prediction
</span>                <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">future_x</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="sh">'</span><span class="s">r--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Prediction</span><span class="sh">'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                
                <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Stock </span><span class="si">{</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
                <span class="n">ax</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
            
            <span class="c1"># Hide last subplot
</span>            <span class="k">if</span> <span class="n">n_features</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">:</span>
                <span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
            
            <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
            <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Visualize results
</span><span class="n">test_loader</span> <span class="o">=</span> <span class="nf">create_dataloader</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">plot_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">scaler</span><span class="p">)</span>

<span class="c1"># Plot training curves
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train Loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation Loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Training Curves</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Train Loss (Last 20)</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation Loss (Last 20)</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Recent Training Curves</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="6-performance-evaluation">6. Performance Evaluation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">scaler</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Evaluate model performance</span><span class="sh">"""</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    
    <span class="n">all_predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="n">batch_X</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
            
            <span class="n">all_predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
            <span class="n">all_targets</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch_y</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
    
    <span class="c1"># Combine predictions and targets
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">all_targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Inverse normalization
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">inverse_transform</span><span class="p">(</span><span class="n">targets</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    
    <span class="c1"># Calculate MSE, MAE
</span>    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">((</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">targets</span><span class="p">))</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Test Performance:</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse</span><span class="p">,</span> <span class="n">mae</span><span class="p">,</span> <span class="n">rmse</span>

<span class="c1"># Evaluate performance
</span><span class="n">mse</span><span class="p">,</span> <span class="n">mae</span><span class="p">,</span> <span class="n">rmse</span> <span class="o">=</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">scaler</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="-model-comparison-and-selection-guide">üìä Model Comparison and Selection Guide</h2>

<h3 id="performance-comparison">Performance Comparison</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Advantages</th>
      <th>Disadvantages</th>
      <th>Application Areas</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Informer</strong></td>
      <td>Efficient on long sequences, strong performance</td>
      <td>Complex structure, long training time</td>
      <td>Long-term prediction, large-scale data</td>
    </tr>
    <tr>
      <td><strong>Autoformer</strong></td>
      <td>Automatic periodicity learning, interpretable</td>
      <td>Limited on non-periodic data</td>
      <td>Seasonal data, business analysis</td>
    </tr>
    <tr>
      <td><strong>FEDformer</strong></td>
      <td>Frequency domain processing, ensemble</td>
      <td>FFT computation cost</td>
      <td>Signal processing, periodic data</td>
    </tr>
    <tr>
      <td><strong>PatchTST</strong></td>
      <td>Simple and efficient, fast training</td>
      <td>Sensitive to patch size</td>
      <td>Real-time prediction, multivariate time series</td>
    </tr>
  </tbody>
</table>

<h3 id="model-selection-guide">Model Selection Guide</h3>

<p><strong>1. Based on Data Characteristics:</strong></p>
<ul>
  <li><strong>Strongly periodic data</strong>: Autoformer, FEDformer</li>
  <li><strong>Long sequence data</strong>: Informer, PatchTST</li>
  <li><strong>Multivariate time series</strong>: PatchTST, Informer</li>
  <li><strong>Real-time prediction</strong>: PatchTST</li>
</ul>

<p><strong>2. Based on Resource Constraints:</strong></p>
<ul>
  <li><strong>Limited computational resources</strong>: PatchTST</li>
  <li><strong>Sufficient resources</strong>: Informer, FEDformer</li>
  <li><strong>Fast prototyping</strong>: PatchTST</li>
</ul>

<h2 id="-next-steps">üéØ Next Steps</h2>

<p>In this part, we explored transformer-based time series forecasting models. In the next parts:</p>

<ul>
  <li><strong>Part 4</strong>: Latest generative AI models (TimeGPT, Lag-Llama, Moirai, Chronos)</li>
  <li><strong>Part 5</strong>: Practical application and MLOps (model deployment, monitoring, A/B testing)</li>
</ul>

<h2 id="-key-takeaways">üí° Key Takeaways</h2>

<ol>
  <li><strong>Transformer Advantages</strong>: Parallel processing, long-range dependency learning, scalability</li>
  <li><strong>Model-specific Characteristics</strong>: Each model has unique strengths and application areas</li>
  <li><strong>Practical Considerations</strong>: Consider data characteristics, resource constraints, and performance requirements comprehensively</li>
  <li><strong>Importance of Practice</strong>: Learn theory and code together to improve practical application skills</li>
</ol>

<p>Transformer-based models present a new paradigm for time series forecasting. Join us in the next part to explore even more interesting cutting-edge models!</p>

<hr />

<h2 id="-series-navigation">üîó Series Navigation</h2>

<p><strong>‚Üê Previous</strong>: <a href="/en_posts/2025-09-01-time-series-deep-learning.html">Part 2: Deep Learning-based Time Series Forecasting - N-BEATS and DeepAR</a></p>

<p><strong>Next ‚Üí</strong>: <a href="/en_posts/2025-09-07-time-series-llm-models.html">Part 4: Latest Generative AI Models - TimeGPT, Lag-Llama, Moirai, Chronos</a></p>

<hr />

<p><strong>Next Part Preview</strong>: In Part 4, we‚Äôll explore how the latest generative AI models like TimeGPT and Lag-Llama are being utilized for time series forecasting. üöÄ</p>

  </div>

  
  <div class="post-navigation">
    <div class="nav-links">
      
      
      
        
      
        
      
        
      
        
      
        
      
      
      
      
      
        
        
        <a href="/data-ai/2025/09/07/time-series-llm-models.html" class="nav-link next">
          Îã§Ïùå: Part 4: ÏµúÏã† ÏÉùÏÑ±Ìòï AI Î™®Îç∏Îì§ - TimeGPT, Lag-Llama, Moirai, Chronos ‚Üí
        </a>
      
    </div>
    
    <div class="series-overview">
      <a href="/categories/data-ai/" class="btn btn-secondary">
        üìö ÏãúÎ¶¨Ï¶à Ï†ÑÏ≤¥ Î≥¥Í∏∞
      </a>
    </div>
  </div>
  
</article>

    </div>
  </main>
  
  
  <footer class="site-footer">
  <div class="container">
    <div class="footer-content">
      <div class="footer-section">
        <h3>Data Droid Blog</h3>
        <p>Îç∞Ïù¥ÌÑ∞ ÏóîÏßÄÎãàÏñ¥Í∞Ä Îã§Î£®Îäî Í∏∞Ïà† Î∏îÎ°úÍ∑∏</p>
      </div>
      
      <div class="footer-section">
        <h4>Categories</h4>
        <ul>
          <li><a href="/en/categories/data-engineering/">Data Engineering</a></li>
          <li><a href="/en/categories/bi-engineering/">BI Engineering</a></li>
          <li><a href="/en/categories/infrastructure-tools/">Infrastructure & Tools</a></li>
          <li><a href="/en/categories/data-quality/">Data Quality</a></li>
          <li><a href="/en/categories/data-ai/">Data AI</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>Links</h4>
        <ul>
          <li><a href="/en/">Home</a></li>
          <li><a href="/en/blog/">Blog</a></li>
          <li><a href="/en/about/">About</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>Social</h4>
        <ul>
          
          <li><a href="https://github.com/data-droid">GitHub</a></li>
          
          <li><a href="https://www.linkedin.com/in/jaekyung-lee/">LinkedIn</a></li>
        </ul>
      </div>
    </div>
    
    <div class="footer-bottom">
      <p>&copy; 2025 Data Droid Blog. All rights reserved</p>
    </div>
  </div>
</footer>



  
  <script src="/assets/js/main.js"></script>
</body>
</html>
