<!DOCTYPE html>
<html lang="ko">
<head>
  <link rel="stylesheet" href="/assets/css/style.css">
  <!-- Head includes for Jekyll -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- SEO -->

<meta name="description" content="대규모 언어 모델을 활용한 혁신적인 시계열 예측 모델들을 살펴보고 실제 구현해봅니다.">



<title>Part 4: 최신 생성형 AI 모델들 - TimeGPT, Lag-Llama, Moirai, Chronos - Data Droid Blog</title>


<!-- Open Graph -->
<meta property="og:title" content="Part 4: 최신 생성형 AI 모델들 - TimeGPT, Lag-Llama, Moirai, Chronos">
<meta property="og:description" content="대규모 언어 모델을 활용한 혁신적인 시계열 예측 모델들을 살펴보고 실제 구현해봅니다.">
<meta property="og:url" content="http://localhost:4000/data-ai/2025/09/07/time-series-llm-models.html">
<meta property="og:type" content="website">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Part 4: 최신 생성형 AI 모델들 - TimeGPT, Lag-Llama, Moirai, Chronos">
<meta name="twitter:description" content="대규모 언어 모델을 활용한 혁신적인 시계열 예측 모델들을 살펴보고 실제 구현해봅니다.">

<!-- Favicon -->
<link rel="icon" type="image/svg+xml" href="/assets/favicon.svg">
<link rel="icon" type="image/x-icon" href="/favicon.ico">

<!-- RSS Feed -->
<link rel="alternate" type="application/rss+xml" title="Data Droid Blog" href="/feed.xml">

<!-- Google Analytics -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GP9LT745PP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GP9LT745PP');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <div class="site-title">
      <a href="/">Data Droid Blog</a>
    </div>
    
    <!-- Mobile menu toggle button -->
    <button class="mobile-menu-toggle" aria-label="메뉴 열기/닫기">
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
      <span class="hamburger-line"></span>
    </button>
    
    <nav class="site-nav">
      <ul class="nav-list">
        <li><a href="/">홈</a></li>
                  <li class="dropdown">
            <a href="#" class="dropdown-toggle">카테고리</a>
            <ul class="dropdown-menu">

              <li><a href="/categories/data-engineering/">데이터 엔지니어링</a></li>
              <li><a href="/categories/bi-engineering/">BI 엔지니어링</a></li>
              <li><a href="/categories/infrastructure-tools/">인프라 & 도구</a></li>
              <li><a href="/categories/data-quality/">데이터 품질</a></li>
              <li><a href="/categories/data-ai/">Data AI</a></li>
            </ul>
          </li>
        <li><a href="/blog/">블로그</a></li>
        <li><a href="/about/">소개</a></li>
      </ul>
    </nav>
    
    <div class="language-switcher">
      
        <!-- 포스트용 언어 전환 -->
        
          <a href="/data-ai/2025/09/07/time-series-llm-models.html" class="lang-btn active">한국어</a>
          
          <a href="/en_posts/2025-09-07-time-series-llm-models.html" class="lang-btn">English</a>
        
      
    </div>
  </div>
</header>

  
  <main class="site-main">
    <div class="container">
      <article class="post">
  <header class="post-header">
    <div class="post-meta">
      <span class="post-category">Data ai</span>
      <span class="post-date">2025년 09월 07일</span>
      <span class="post-author">Data Droid</span>
    </div>
    
    <h1 class="post-title">Part 4: 최신 생성형 AI 모델들 - TimeGPT, Lag-Llama, Moirai, Chronos</h1>
    
    
    <div class="post-tags">
      
        <span class="tag">시계열예측</span>
      
        <span class="tag">LLM</span>
      
        <span class="tag">TimeGPT</span>
      
        <span class="tag">Lag-Llama</span>
      
        <span class="tag">Moirai</span>
      
        <span class="tag">Chronos</span>
      
        <span class="tag">생성형AI</span>
      
        <span class="tag">대규모언어모델</span>
      
    </div>
    
    
    
    <div class="post-series">
      <span class="series-badge">📚 Time series forecasting 시리즈</span>
      <span class="series-order">Part 5</span>
    </div>
    
    
    
    <div class="post-info">
      
        <span class="reading-time">⏱️ 20분</span>
      
      
        <span class="difficulty">📊 고급</span>
      
    </div>
    
  </header>

  <div class="post-content">
    <h1 id="part-4-최신-생성형-ai-모델들---timegpt-lag-llama-moirai-chronos">Part 4: 최신 생성형 AI 모델들 - TimeGPT, Lag-Llama, Moirai, Chronos</h1>

<blockquote>
  <p>대규모 언어 모델을 활용한 혁신적인 시계열 예측 모델들을 살펴보고 실제 구현해봅니다.</p>
</blockquote>

<h2 id="목차">📋 목차</h2>

<ol>
  <li><a href="#llm-기반-시계열-예측의-등장">LLM 기반 시계열 예측의 등장</a></li>
  <li><a href="#timegpt-openai의-시계열-예측-모델">TimeGPT: OpenAI의 시계열 예측 모델</a></li>
  <li><a href="#lag-llama-오픈소스-대안">Lag-Llama: 오픈소스 대안</a></li>
  <li><a href="#moirai-다중-시계열-예측">Moirai: 다중 시계열 예측</a></li>
  <li><a href="#chronos-메타의-시계열-모델">Chronos: 메타의 시계열 모델</a></li>
  <li><a href="#실습-lag-llama-구현-및-활용">실습: Lag-Llama 구현 및 활용</a></li>
  <li><a href="#모델-비교-및-선택-가이드">모델 비교 및 선택 가이드</a></li>
  <li><a href="#다음-단계-및-미래-전망">다음 단계 및 미래 전망</a></li>
  <li><a href="#학습-요약">학습 요약</a></li>
</ol>

<h2 id="llm-기반-시계열-예측의-등장">🚀 LLM 기반 시계열 예측의 등장</h2>

<h3 id="기존-모델들의-한계">기존 모델들의 한계</h3>

<p>Part 1-3에서 학습한 모델들은 각각의 장점이 있었지만, 다음과 같은 공통적인 한계가 있었습니다:</p>

<ol>
  <li><strong>도메인 특화</strong>: 특정 시계열 패턴에만 최적화</li>
  <li><strong>데이터 의존성</strong>: 대량의 도메인별 학습 데이터 필요</li>
  <li><strong>일반화 한계</strong>: 새로운 시계열 유형에 대한 적응 어려움</li>
  <li><strong>멀티태스킹 부족</strong>: 다양한 예측 작업을 동시에 수행하기 어려움</li>
</ol>

<h3 id="llm의-혁신적-접근">LLM의 혁신적 접근</h3>

<p>대규모 언어 모델(LLM)은 이러한 한계를 극복하는 새로운 패러다임을 제시했습니다:</p>

<ul>
  <li><strong>범용성</strong>: 다양한 도메인의 시계열 데이터 학습</li>
  <li><strong>Few-shot Learning</strong>: 적은 데이터로도 우수한 성능</li>
  <li><strong>멀티태스킹</strong>: 여러 예측 작업을 동시에 수행</li>
  <li><strong>자연어 인터페이스</strong>: 직관적인 질의 및 설명 가능</li>
</ul>

<h3 id="핵심-기술적-혁신">핵심 기술적 혁신</h3>

<ol>
  <li><strong>Tokenization</strong>: 시계열 데이터를 토큰으로 변환</li>
  <li><strong>Causal Attention</strong>: 시계열의 시간적 의존성 모델링</li>
  <li><strong>Multi-scale Learning</strong>: 다양한 시간 스케일의 패턴 학습</li>
  <li><strong>Instruction Following</strong>: 자연어 지시사항에 따른 예측</li>
</ol>

<h2 id="-timegpt-openai의-시계열-예측-모델">🤖 TimeGPT: OpenAI의 시계열 예측 모델</h2>

<h3 id="timegpt의-핵심-특징">TimeGPT의 핵심 특징</h3>

<p>TimeGPT는 OpenAI에서 개발한 최초의 대규모 시계열 예측 모델입니다.</p>

<h4 id="1-대규모-사전-훈련"><strong>1. 대규모 사전 훈련</strong></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>훈련 데이터: 1000억 개 이상의 시계열 데이터 포인트
도메인: 금융, 소매, 제조업, 에너지, 의료 등
지리적 범위: 전 세계
시간 범위: 2020년-2024년
</code></pre></div></div>

<h4 id="2-zero-shot-예측-능력"><strong>2. Zero-shot 예측 능력</strong></h4>

<p>TimeGPT는 사전 훈련된 지식을 바탕으로 새로운 시계열에 대해 추가 학습 없이 예측할 수 있습니다:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 예시: 새로운 시계열에 대한 즉시 예측
</span><span class="n">forecast</span> <span class="o">=</span> <span class="n">timegpt</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span>
    <span class="n">series</span><span class="o">=</span><span class="n">unseen_timeseries</span><span class="p">,</span>
    <span class="n">horizon</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>  <span class="c1"># 30일 예측
</span>    <span class="n">freq</span><span class="o">=</span><span class="sh">"</span><span class="s">D</span><span class="sh">"</span>     <span class="c1"># 일별 데이터
</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="3-자연어-인터페이스"><strong>3. 자연어 인터페이스</strong></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 자연어로 예측 요청
</span><span class="n">result</span> <span class="o">=</span> <span class="n">timegpt</span><span class="p">.</span><span class="nf">predict_with_context</span><span class="p">(</span>
    <span class="n">series</span><span class="o">=</span><span class="n">stock_prices</span><span class="p">,</span>
    <span class="n">context</span><span class="o">=</span><span class="sh">"</span><span class="s">주식 가격을 1주일 예측해주세요. 시장 변동성을 고려해서요.</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">horizon</span><span class="o">=</span><span class="mi">7</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="timegpt의-아키텍처">TimeGPT의 아키텍처</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>입력 시계열 → Tokenization → Transformer Encoder → Decoder → 예측값
     ↓              ↓              ↓              ↓
  Raw Data    Time Tokens    Attention      Forecast
</code></pre></div></div>

<h4 id="tokenization-전략"><strong>Tokenization 전략</strong></h4>

<ol>
  <li><strong>Value Binning</strong>: 연속값을 이산 토큰으로 변환</li>
  <li><strong>Temporal Encoding</strong>: 시간 정보를 토큰에 포함</li>
  <li><strong>Context Tokens</strong>: 메타데이터를 토큰으로 표현</li>
</ol>

<h2 id="-lag-llama-오픈소스-대안">🦙 Lag-Llama: 오픈소스 대안</h2>

<h3 id="lag-llama의-등장-배경">Lag-Llama의 등장 배경</h3>

<p>TimeGPT가 상용 모델이면서 API 기반으로만 제공되는 한계를 극복하기 위해 Hugging Face에서 개발한 오픈소스 모델입니다.</p>

<h4 id="1-오픈소스-접근성"><strong>1. 오픈소스 접근성</strong></h4>

<ul>
  <li><strong>완전 오픈소스</strong>: 모델 가중치와 코드 공개</li>
  <li><strong>로컬 실행</strong>: API 의존성 없이 로컬에서 실행</li>
  <li><strong>커스터마이징</strong>: 필요에 따라 모델 수정 가능</li>
</ul>

<h4 id="2-llama-기반-아키텍처"><strong>2. LLaMA 기반 아키텍처</strong></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>시계열 입력 → Lag Features → LLaMA-7B → 예측값
     ↓            ↓            ↓
  Raw Data    Lag Tokens    Transformer
</code></pre></div></div>

<h4 id="3-lag-features의-혁신"><strong>3. Lag Features의 혁신</strong></h4>

<p>Lag-Llama는 시계열의 지연값(lag values)을 토큰으로 변환합니다:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Lag Features 생성 예시
</span><span class="k">def</span> <span class="nf">create_lag_features</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">max_lags</span><span class="o">=</span><span class="mi">24</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">시계열에서 지연 특성 생성</span><span class="sh">"""</span>
    <span class="n">lags</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_lags</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">lags</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">series</span><span class="p">.</span><span class="nf">shift</span><span class="p">(</span><span class="n">lag</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">lags</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="lag-llama의-장점">Lag-Llama의 장점</h3>

<ol>
  <li><strong>투명성</strong>: 모델 구조와 학습 과정 공개</li>
  <li><strong>비용 효율성</strong>: API 비용 없이 사용 가능</li>
  <li><strong>개인정보 보호</strong>: 데이터가 외부로 전송되지 않음</li>
  <li><strong>확장성</strong>: 다양한 도메인에 맞춤화 가능</li>
</ol>

<h2 id="-moirai-다중-시계열-예측">🌊 Moirai: 다중 시계열 예측</h2>

<h3 id="moirai의-핵심-개념">Moirai의 핵심 개념</h3>

<p>Moirai는 여러 시계열을 동시에 예측하는 멀티태스킹 모델입니다.</p>

<h4 id="1-멀티태스킹-아키텍처"><strong>1. 멀티태스킹 아키텍처</strong></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>시계열 1 ┐
시계열 2 ├─→ Shared Encoder → Task-specific Heads → 예측값들
시계열 3 ┘
</code></pre></div></div>

<h4 id="2-cross-series-learning"><strong>2. Cross-series Learning</strong></h4>

<ul>
  <li><strong>공통 패턴 학습</strong>: 여러 시계열 간의 공통 패턴 발견</li>
  <li><strong>지식 전이</strong>: 한 시계열의 학습이 다른 시계열에 도움</li>
  <li><strong>효율성</strong>: 단일 모델로 여러 시계열 처리</li>
</ul>

<h4 id="3-hierarchical-forecasting"><strong>3. Hierarchical Forecasting</strong></h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>국가 수준 ┐
지역 수준 ├─→ 계층적 예측
도시 수준 ┘
</code></pre></div></div>

<h2 id="-chronos-메타의-시계열-모델">⏰ Chronos: 메타의 시계열 모델</h2>

<h3 id="chronos의-혁신적-접근">Chronos의 혁신적 접근</h3>

<p>Chronos는 메타에서 개발한 토큰 기반 시계열 예측 모델입니다.</p>

<h4 id="1-token-based-forecasting"><strong>1. Token-based Forecasting</strong></h4>

<p>시계열을 토큰으로 변환하여 언어 모델처럼 처리:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Chronos 토큰화 예시
</span><span class="k">def</span> <span class="nf">tokenize_timeseries</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">시계열을 토큰으로 변환</span><span class="sh">"""</span>
    <span class="c1"># 값 정규화
</span>    <span class="n">normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">series</span> <span class="o">-</span> <span class="n">series</span><span class="p">.</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">series</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>
    
    <span class="c1"># 양자화
</span>    <span class="n">quantized</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">digitize</span><span class="p">(</span><span class="n">normalized</span><span class="p">,</span> 
                          <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">quantized</span>
</code></pre></div></div>

<h4 id="2-multi-scale-learning"><strong>2. Multi-scale Learning</strong></h4>

<ul>
  <li><strong>단기 패턴</strong>: 일별, 주별 변동</li>
  <li><strong>중기 패턴</strong>: 월별, 분기별 트렌드</li>
  <li><strong>장기 패턴</strong>: 연간 계절성, 구조적 변화</li>
</ul>

<h4 id="3-instruction-tuning"><strong>3. Instruction Tuning</strong></h4>

<p>자연어 지시사항에 따라 다양한 예측 작업 수행:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Chronos 지시사항 예시
</span><span class="n">instructions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">다음 7일의 매출을 예측해주세요</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">계절성을 고려한 월별 예측을 해주세요</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">이상치를 제외한 안정적인 예측을 해주세요</span><span class="sh">"</span>
<span class="p">]</span>
</code></pre></div></div>

<h2 id="실습-lag-llama-구현-및-활용">🛠 ️ 실습: Lag-Llama 구현 및 활용</h2>

<h3 id="1-환경-설정">1. 환경 설정</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 필요한 라이브러리 설치
# pip install transformers torch datasets evaluate
# pip install pandas numpy matplotlib seaborn
# pip install scikit-learn
</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># 시각화 설정
</span><span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">'</span><span class="s">seaborn-v0_8</span><span class="sh">'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">set_palette</span><span class="p">(</span><span class="sh">"</span><span class="s">husl</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-lag-llama-모델-로드">2. Lag-Llama 모델 로드</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Lag-Llama 모델 로드
</span><span class="n">model_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">time-series-foundation-models/Lag-Llama</span><span class="sh">"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">모델 파라미터 수: </span><span class="si">{</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">모델 구조: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-시계열-데이터-준비">3. 시계열 데이터 준비</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_complex_multivariate_timeseries</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">n_series</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">복잡한 다변량 시계열 데이터 생성</span><span class="sh">"""</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="c1"># 시간 인덱스
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    
    <span class="c1"># 공통 트렌드
</span>    <span class="n">common_trend</span> <span class="o">=</span> <span class="mf">0.02</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">0.0001</span> <span class="o">*</span> <span class="n">t</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="c1"># 시계열별 특성
</span>    <span class="n">series_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_series</span><span class="p">):</span>
        <span class="c1"># 시계열별 고유 패턴
</span>        <span class="n">series_trend</span> <span class="o">=</span> <span class="n">common_trend</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">i</span> <span class="o">*</span> <span class="n">t</span>
        <span class="n">series_seasonal</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="mi">365</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">series_noise</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        
        <span class="c1"># 시계열 간 상관관계
</span>        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">correlation</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">t</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">series_data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">series_trend</span> <span class="o">+</span> <span class="n">series_seasonal</span> <span class="o">+</span> <span class="n">series_noise</span> <span class="o">+</span> <span class="n">correlation</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">series_data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">series_trend</span> <span class="o">+</span> <span class="n">series_seasonal</span> <span class="o">+</span> <span class="n">series_noise</span><span class="p">)</span>
    
    <span class="c1"># 데이터프레임 생성
</span>    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">series_data</span><span class="p">).</span><span class="n">T</span><span class="p">,</span> 
                     <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">series_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="sh">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_series</span><span class="p">)],</span>
                     <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nf">date_range</span><span class="p">(</span><span class="sh">'</span><span class="s">2020-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="n">periods</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># 다변량 시계열 생성
</span><span class="n">multivariate_ts</span> <span class="o">=</span> <span class="nf">generate_complex_multivariate_timeseries</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">multivariate_ts</span><span class="p">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">multivariate_ts</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">multivariate_ts</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s"> 시계열</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">값</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">시계열 개수: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">multivariate_ts</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">데이터 길이: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">multivariate_ts</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">값 범위: </span><span class="si">{</span><span class="n">multivariate_ts</span><span class="p">.</span><span class="nf">min</span><span class="p">().</span><span class="nf">min</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> ~ </span><span class="si">{</span><span class="n">multivariate_ts</span><span class="p">.</span><span class="nf">max</span><span class="p">().</span><span class="nf">max</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="4-lag-features-생성">4. Lag Features 생성</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_lag_features</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_lags</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Lag-Llama용 지연 특성 생성</span><span class="sh">"""</span>
    <span class="n">lag_features</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">series</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">values</span>
        
        <span class="c1"># 지연 특성 생성
</span>        <span class="n">lags</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_lags</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">lag_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">roll</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">lag</span><span class="p">)</span>
            <span class="n">lag_values</span><span class="p">[:</span><span class="n">lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>  <span class="c1"># 처음 lag개는 NaN
</span>            <span class="n">lags</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">lag_values</span><span class="p">)</span>
        
        <span class="n">lag_features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">column_stack</span><span class="p">(</span><span class="n">lags</span><span class="p">)</span>
        
        <span class="c1"># 타겟 생성 (미래 값)
</span>        <span class="n">targets</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">forecast_horizon</span><span class="p">:]</span>
    
    <span class="k">return</span> <span class="n">lag_features</span><span class="p">,</span> <span class="n">targets</span>

<span class="c1"># Lag features 생성
</span><span class="n">max_lags</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">forecast_horizon</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">lag_features</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="nf">create_lag_features</span><span class="p">(</span><span class="n">multivariate_ts</span><span class="p">,</span> <span class="n">max_lags</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Lag features 형태: </span><span class="si">{</span><span class="n">lag_features</span><span class="p">[</span><span class="sh">'</span><span class="s">series_1</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Targets 형태: </span><span class="si">{</span><span class="n">targets</span><span class="p">[</span><span class="sh">'</span><span class="s">series_1</span><span class="sh">'</span><span class="p">].</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="5-lag-llama-모델-구현">5. Lag-Llama 모델 구현</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LagLlamaPredictor</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Lag-Llama 기반 시계열 예측 모델</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LagLlamaPredictor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        
        <span class="c1"># 입력 임베딩
</span>        <span class="n">self</span><span class="p">.</span><span class="n">input_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        
        <span class="c1"># Transformer 레이어들
</span>        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span>
        
        <span class="c1"># 출력 레이어
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        
        <span class="c1"># 드롭아웃
</span>        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 입력 임베딩
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">input_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Transformer 인코더
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># 마지막 시점의 출력 사용
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, hidden_dim)
</span>        
        <span class="c1"># 출력 예측
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output</span>

<span class="c1"># 모델 생성
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">LagLlamaPredictor</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="n">max_lags</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span>
<span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Lag-Llama 모델 파라미터 수: </span><span class="si">{</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="6-데이터-전처리-및-학습">6. 데이터 전처리 및 학습</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prepare_training_data</span><span class="p">(</span><span class="n">lag_features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">train_ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">학습 데이터 준비</span><span class="sh">"""</span>
    <span class="n">all_X</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_y</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">lag_features</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">lag_features</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
        
        <span class="c1"># NaN 제거
</span>        <span class="n">valid_indices</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">]</span>
        
        <span class="c1"># 길이 맞추기
</span>        <span class="n">min_len</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">min_len</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">min_len</span><span class="p">]</span>
        
        <span class="n">all_X</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">all_y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># 모든 시계열 결합
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">(</span><span class="n">all_X</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">(</span><span class="n">all_y</span><span class="p">)</span>
    
    <span class="c1"># 학습/검증 분할
</span>    <span class="n">split_idx</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">train_ratio</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span>

<span class="c1"># 데이터 준비
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="nf">prepare_training_data</span><span class="p">(</span><span class="n">lag_features</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="c1"># PyTorch 텐서로 변환
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">X_val</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">y_val</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">학습 데이터: </span><span class="si">{</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">검증 데이터: </span><span class="si">{</span><span class="n">X_val</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">y_val</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 학습 함수
</span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">모델 학습</span><span class="sh">"""</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># 학습
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        
        <span class="n">train_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">train_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        
        <span class="c1"># 검증
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">val_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">val_pred</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
        
        <span class="n">train_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        <span class="n">val_losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        
        <span class="c1"># Learning rate 스케줄링
</span>        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        
        <span class="nf">if </span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">] - Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="s">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">6</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span>

<span class="c1"># 모델 학습
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=== Lag-Llama 모델 학습 시작 ===</span><span class="sh">"</span><span class="p">)</span>
<span class="n">train_losses</span><span class="p">,</span> <span class="n">val_losses</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># 학습 과정 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Training Loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Validation Loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Lag-Llama 모델 학습 과정</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Epoch</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss (MSE)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="7-예측-및-성능-평가">7. 예측 및 성능 평가</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="sh">"</span><span class="s">Lag-Llama</span><span class="sh">"</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">모델 성능 평가</span><span class="sh">"""</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()</span>
    
    <span class="c1"># 성능 지표 계산
</span>    <span class="n">mse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s"> 성능:</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="p">(</span><span class="n">mse</span><span class="p">,</span> <span class="n">mae</span><span class="p">,</span> <span class="n">rmse</span><span class="p">)</span>

<span class="c1"># 성능 평가
</span><span class="n">predictions</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

<span class="c1"># 예측 결과 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># 첫 200개 샘플의 예측 vs 실제값
</span><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_val</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">].</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">실제값</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">predictions</span><span class="p">[:</span><span class="n">sample_size</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Lag-Llama 예측</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Lag-Llama: 예측 vs 실제값 (첫 200개 샘플)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">샘플</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">값</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 산점도
</span><span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">y_val</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="n">y_val</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">y_val</span><span class="p">.</span><span class="nf">max</span><span class="p">()],</span> <span class="p">[</span><span class="n">y_val</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">y_val</span><span class="p">.</span><span class="nf">max</span><span class="p">()],</span> <span class="sh">'</span><span class="s">r--</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">실제값</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">예측값</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">실제값 vs 예측값 산점도</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="8-다중-시계열-예측">8. 다중 시계열 예측</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_multiple_series</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">multivariate_ts</span><span class="p">,</span> <span class="n">max_lags</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">forecast_horizon</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">다중 시계열 예측</span><span class="sh">"""</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">multivariate_ts</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">series</span> <span class="o">=</span> <span class="n">multivariate_ts</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="n">values</span>
        
        <span class="c1"># 최근 데이터로 lag features 생성
</span>        <span class="n">recent_data</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="n">max_lags</span><span class="p">:]</span>
        <span class="n">recent_data</span> <span class="o">=</span> <span class="n">recent_data</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># 예측
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">FloatTensor</span><span class="p">(</span><span class="n">recent_data</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">predictions</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">predictions</span>

<span class="c1"># 다중 시계열 예측
</span><span class="n">forecast_predictions</span> <span class="o">=</span> <span class="nf">predict_multiple_series</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">multivariate_ts</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=== 다중 시계열 예측 결과 ===</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">forecast_predictions</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 예측 결과 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">forecast_predictions</span><span class="p">.</span><span class="nf">items</span><span class="p">()):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># 최근 100일 데이터
</span>    <span class="n">recent_data</span> <span class="o">=</span> <span class="n">multivariate_ts</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">tail</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">recent_data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">recent_data</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">과거 데이터</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    
    <span class="c1"># 예측값
</span>    <span class="n">last_date</span> <span class="o">=</span> <span class="n">recent_data</span><span class="p">.</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">next_date</span> <span class="o">=</span> <span class="n">last_date</span> <span class="o">+</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> 
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">예측값: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s"> - 다음 예측값: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">값</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="모델-비교-및-선택-가이드">📊 모델 비교 및 선택 가이드</h2>

<h3 id="성능-비교">성능 비교</h3>

<table>
  <thead>
    <tr>
      <th>모델</th>
      <th>장점</th>
      <th>단점</th>
      <th>사용 사례</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>TimeGPT</strong></td>
      <td>최고 성능, 자연어 인터페이스</td>
      <td>API 의존성, 비용</td>
      <td>상용 서비스, 프로토타이핑</td>
    </tr>
    <tr>
      <td><strong>Lag-Llama</strong></td>
      <td>오픈소스, 로컬 실행</td>
      <td>성능 제한, 설정 복잡</td>
      <td>연구, 개인 프로젝트</td>
    </tr>
    <tr>
      <td><strong>Moirai</strong></td>
      <td>다중 시계열, 효율성</td>
      <td>복잡한 아키텍처</td>
      <td>대규모 다변량 예측</td>
    </tr>
    <tr>
      <td><strong>Chronos</strong></td>
      <td>토큰 기반, 유연성</td>
      <td>메타 의존성</td>
      <td>실험적 연구</td>
    </tr>
  </tbody>
</table>

<h3 id="선택-가이드">선택 가이드</h3>

<h4 id="1-프로젝트-규모별"><strong>1. 프로젝트 규모별</strong></h4>

<ul>
  <li><strong>소규모</strong>: Lag-Llama (오픈소스, 무료)</li>
  <li><strong>중규모</strong>: TimeGPT (API, 빠른 구현)</li>
  <li><strong>대규모</strong>: Moirai (다중 시계열, 효율성)</li>
</ul>

<h4 id="2-요구사항별"><strong>2. 요구사항별</strong></h4>

<ul>
  <li><strong>정확도 우선</strong>: TimeGPT</li>
  <li><strong>비용 효율성</strong>: Lag-Llama</li>
  <li><strong>다중 시계열</strong>: Moirai</li>
  <li><strong>실험적 연구</strong>: Chronos</li>
</ul>

<h4 id="3-기술적-고려사항"><strong>3. 기술적 고려사항</strong></h4>

<ul>
  <li><strong>데이터 프라이버시</strong>: Lag-Llama (로컬 실행)</li>
  <li><strong>빠른 프로토타이핑</strong>: TimeGPT (API)</li>
  <li><strong>커스터마이징</strong>: Lag-Llama (오픈소스)</li>
  <li><strong>확장성</strong>: Moirai (멀티태스킹)</li>
</ul>

<h2 id="다음-단계-및-미래-전망">🚀 다음 단계 및 미래 전망</h2>

<h3 id="기술-발전-방향">기술 발전 방향</h3>

<ol>
  <li><strong>더 큰 모델</strong>: 수조 개 파라미터의 시계열 모델</li>
  <li><strong>멀티모달</strong>: 텍스트, 이미지, 시계열 통합</li>
  <li><strong>실시간 학습</strong>: 스트리밍 데이터에서 지속적 학습</li>
  <li><strong>설명 가능성</strong>: 예측 근거의 자연어 설명</li>
</ol>

<h3 id="실무-적용-고려사항">실무 적용 고려사항</h3>

<ol>
  <li><strong>데이터 품질</strong>: LLM도 고품질 데이터 필요</li>
  <li><strong>비용 관리</strong>: API 사용량 모니터링</li>
  <li><strong>모델 업데이트</strong>: 정기적인 재학습 필요</li>
  <li><strong>성능 모니터링</strong>: 지속적인 성능 추적</li>
</ol>

<h3 id="미래-연구-방향">미래 연구 방향</h3>

<ol>
  <li><strong>Few-shot Learning</strong>: 더 적은 데이터로 학습</li>
  <li><strong>Transfer Learning</strong>: 도메인 간 지식 전이</li>
  <li><strong>Causal Learning</strong>: 인과관계 기반 예측</li>
  <li><strong>Uncertainty Quantification</strong>: 불확실성 정량화</li>
</ol>

<h2 id="학습-요약">📚 학습 요약</h2>

<h3 id="이번-파트에서-학습한-내용">이번 파트에서 학습한 내용</h3>

<ol>
  <li><strong>LLM 기반 시계열 예측의 등장</strong>
    <ul>
      <li>기존 모델들의 한계</li>
      <li>LLM의 혁신적 접근</li>
      <li>핵심 기술적 혁신</li>
    </ul>
  </li>
  <li><strong>주요 모델들</strong>
    <ul>
      <li><strong>TimeGPT</strong>: OpenAI의 상용 모델</li>
      <li><strong>Lag-Llama</strong>: 오픈소스 대안</li>
      <li><strong>Moirai</strong>: 다중 시계열 예측</li>
      <li><strong>Chronos</strong>: 메타의 토큰 기반 모델</li>
    </ul>
  </li>
  <li><strong>실제 구현</strong>
    <ul>
      <li>Lag-Llama 모델 구현</li>
      <li>다중 시계열 예측</li>
      <li>성능 평가 및 비교</li>
    </ul>
  </li>
</ol>

<h3 id="핵심-개념-정리">핵심 개념 정리</h3>

<table>
  <thead>
    <tr>
      <th>개념</th>
      <th>설명</th>
      <th>중요도</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Tokenization</strong></td>
      <td>시계열을 토큰으로 변환</td>
      <td>⭐⭐⭐⭐⭐</td>
    </tr>
    <tr>
      <td><strong>Few-shot Learning</strong></td>
      <td>적은 데이터로 학습</td>
      <td>⭐⭐⭐⭐⭐</td>
    </tr>
    <tr>
      <td><strong>Multi-task Learning</strong></td>
      <td>여러 작업 동시 수행</td>
      <td>⭐⭐⭐⭐</td>
    </tr>
    <tr>
      <td><strong>Zero-shot Prediction</strong></td>
      <td>추가 학습 없이 예측</td>
      <td>⭐⭐⭐⭐⭐</td>
    </tr>
  </tbody>
</table>

<h3 id="실무-적용-시-고려사항">실무 적용 시 고려사항</h3>

<ol>
  <li><strong>모델 선택</strong>: 요구사항에 따른 적절한 모델 선택</li>
  <li><strong>비용 관리</strong>: API 비용과 성능의 균형</li>
  <li><strong>데이터 준비</strong>: 고품질 데이터의 중요성</li>
  <li><strong>성능 모니터링</strong>: 지속적인 모델 성능 추적</li>
</ol>

<hr />

<h2 id="-시리즈-네비게이션">🔗 시리즈 네비게이션</h2>

<p><strong>← 이전</strong>: <a href="/data-ai/2025/09/06/time-series-transformers.html">Part 3: 트랜스포머 기반 시계열 예측 모델들</a></p>

<p><strong>다음 →</strong>: 시리즈 완료! 🎉</p>

<hr />

<p><strong>시리즈 완료</strong>: 시계열 예측의 진화를 ARIMA부터 최신 LLM 모델까지 체계적으로 학습했습니다. 이제 다양한 도구와 기법을 활용하여 실무에서 강력한 시계열 예측 시스템을 구축할 수 있습니다! 🚀</p>

<p><em>이 시리즈를 통해 시계열 예측의 과거, 현재, 미래를 모두 경험했습니다. 각 모델의 특징과 장단점을 이해하고, 실제 데이터에 적용할 수 있는 실무 역량을 기를 수 있었습니다!</em> 🎯</p>

  </div>

  
  <div class="post-navigation">
    <div class="nav-links">
      
      
      
        
      
        
      
        
      
        
      
        
          
          
      
      
        
        
        <a href="/data-ai/2025/09/06/time-series-transformers.html" class="nav-link prev">
          ← 이전: Part 3: 트랜스포머 기반 시계열 예측 모델들
        </a>
      
      
      
    </div>
    
    <div class="series-overview">
      <a href="/categories/data-ai/" class="btn btn-secondary">
        📚 시리즈 전체 보기
      </a>
    </div>
  </div>
  
</article>

    </div>
  </main>
  
  
  <footer class="site-footer">
  <div class="container">
    <div class="footer-content">
      <div class="footer-section">
        <h3>Data Droid Blog</h3>
        <p>데이터 엔지니어가 다루는 기술 블로그</p>
      </div>
      
      <div class="footer-section">
        <h4>카테고리</h4>
        <ul>
          <li><a href="/categories/data-engineering/">데이터 엔지니어링</a></li>
          <li><a href="/categories/bi-engineering/">BI 엔지니어링</a></li>
          <li><a href="/categories/infrastructure-tools/">인프라 & 도구</a></li>
          <li><a href="/categories/data-quality/">데이터 품질</a></li>
          <li><a href="/categories/data-ai/">Data AI</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>링크</h4>
        <ul>
          <li><a href="/">홈</a></li>
          <li><a href="/blog/">블로그</a></li>
          <li><a href="/about/">소개</a></li>
        </ul>
      </div>
      
      <div class="footer-section">
        <h4>소셜</h4>
        <ul>
          
          <li><a href="https://github.com/data-droid">GitHub</a></li>
          
          <li><a href="https://www.linkedin.com/in/jaekyung-lee-a61ab2193/">LinkedIn</a></li>
        </ul>
      </div>
    </div>
    
    <div class="footer-bottom">
      <p>&copy; 2025 Data Droid Blog. 모든 권리 보유</p>
    </div>
  </div>
</footer>



  
  <script src="/assets/js/main.js"></script>
</body>
</html>
